{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2024.2.0)\n",
            "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2021.4.0)\n",
            "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
            "Requirement already satisfied: tbb==2021.* in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.13.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in c:\\users\\lisit\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "WARNING: Skipping c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\numpy-1.24.3.dist-info due to invalid metadata entry 'name'\n",
            "\n",
            "[notice] A new release of pip available: 22.3.1 -> 24.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {
        "id": "Ern2ZiHNW3mo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0WYvTHBaqk7",
        "outputId": "36e538a3-92a4-4e9b-9dcd-263718447e20"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\", force_remount=True)\n",
        "# cd \"/content/drive/MyDrive/Predicta/Competition\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "Dk47Zau-W3mq"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('new_features_added_filled_nearest_neigb_min.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Apk-HwBW3mr",
        "outputId": "80b70d65-5c9e-4d24-ed12-86f7fdfd77cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['city_id', 'date', 'avg_temp_c', 'min_temp_c', 'max_temp_c',\n",
              "       'avg_wind_dir_deg', 'avg_wind_speed_kmh', 'city', 'day_of_week',\n",
              "       'day_of_year', 'month', 'temp_range'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 280,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 281,
      "metadata": {
        "id": "EnFMZ5ZLW3ms"
      },
      "outputs": [],
      "source": [
        "# Python\n",
        "selected_columns_to_exclude = ['date', 'city_id',\n",
        "                               'snow_depth_mm', 'day_of_week']\n",
        "features = [col for col in data.columns if col not in selected_columns_to_exclude]\n",
        "\n",
        "target = 'avg_temp_c'\n",
        "\n",
        "# Scaling features\n",
        "scaler = StandardScaler()\n",
        "# Python\n",
        "numerical_features = data.select_dtypes(include=[np.number]).columns.tolist()\n",
        "data[numerical_features] = scaler.fit_transform(data[numerical_features])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 282,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMKDjT8rKows",
        "outputId": "f2dea009-0a72-4976-c65c-edf8390c9816"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of records: 182338\n",
            "Number of records with at least one null value: 0\n"
          ]
        }
      ],
      "source": [
        "num_rows_with_nulls = data.isnull().any(axis=1).sum()\n",
        "print(f\"Number of records: {len(data)}\")\n",
        "print(f\"Number of records with at least one null value: {num_rows_with_nulls}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DaIIBZhWW3mt",
        "outputId": "ac610aac-25af-4e02-d3fd-8f962e3c48ae"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>city_id</th>\n",
              "      <th>date</th>\n",
              "      <th>avg_temp_c</th>\n",
              "      <th>min_temp_c</th>\n",
              "      <th>max_temp_c</th>\n",
              "      <th>avg_wind_dir_deg</th>\n",
              "      <th>avg_wind_speed_kmh</th>\n",
              "      <th>city</th>\n",
              "      <th>day_of_week</th>\n",
              "      <th>day_of_year</th>\n",
              "      <th>month</th>\n",
              "      <th>temp_range</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>C001</td>\n",
              "      <td>2014-01-01</td>\n",
              "      <td>-1.244652</td>\n",
              "      <td>-1.615164</td>\n",
              "      <td>-1.181246</td>\n",
              "      <td>-0.084152</td>\n",
              "      <td>-0.825328</td>\n",
              "      <td>-1.729156</td>\n",
              "      <td>-0.500611</td>\n",
              "      <td>-1.727467</td>\n",
              "      <td>-1.601858</td>\n",
              "      <td>0.840131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>C001</td>\n",
              "      <td>2014-01-02</td>\n",
              "      <td>-0.974157</td>\n",
              "      <td>-0.843364</td>\n",
              "      <td>-1.017647</td>\n",
              "      <td>-0.212386</td>\n",
              "      <td>-0.202979</td>\n",
              "      <td>-1.729156</td>\n",
              "      <td>-0.000590</td>\n",
              "      <td>-1.717983</td>\n",
              "      <td>-1.601858</td>\n",
              "      <td>-0.472820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>C001</td>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>-1.144469</td>\n",
              "      <td>-1.284393</td>\n",
              "      <td>-0.950283</td>\n",
              "      <td>0.157519</td>\n",
              "      <td>-0.890838</td>\n",
              "      <td>-1.729156</td>\n",
              "      <td>0.499431</td>\n",
              "      <td>-1.708498</td>\n",
              "      <td>-1.601858</td>\n",
              "      <td>0.643188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>C001</td>\n",
              "      <td>2014-01-04</td>\n",
              "      <td>-1.144469</td>\n",
              "      <td>-1.083925</td>\n",
              "      <td>-1.017647</td>\n",
              "      <td>1.129135</td>\n",
              "      <td>0.009929</td>\n",
              "      <td>-1.729156</td>\n",
              "      <td>0.999452</td>\n",
              "      <td>-1.699014</td>\n",
              "      <td>-1.601858</td>\n",
              "      <td>0.052360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>C001</td>\n",
              "      <td>2014-01-05</td>\n",
              "      <td>-1.044286</td>\n",
              "      <td>-1.424720</td>\n",
              "      <td>-0.671204</td>\n",
              "      <td>0.225335</td>\n",
              "      <td>-1.021859</td>\n",
              "      <td>-1.729156</td>\n",
              "      <td>1.499473</td>\n",
              "      <td>-1.689529</td>\n",
              "      <td>-1.601858</td>\n",
              "      <td>1.584136</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  city_id        date  avg_temp_c  min_temp_c  max_temp_c  avg_wind_dir_deg  \\\n",
              "0    C001  2014-01-01   -1.244652   -1.615164   -1.181246         -0.084152   \n",
              "1    C001  2014-01-02   -0.974157   -0.843364   -1.017647         -0.212386   \n",
              "2    C001  2014-01-03   -1.144469   -1.284393   -0.950283          0.157519   \n",
              "3    C001  2014-01-04   -1.144469   -1.083925   -1.017647          1.129135   \n",
              "4    C001  2014-01-05   -1.044286   -1.424720   -0.671204          0.225335   \n",
              "\n",
              "   avg_wind_speed_kmh      city  day_of_week  day_of_year     month  \\\n",
              "0           -0.825328 -1.729156    -0.500611    -1.727467 -1.601858   \n",
              "1           -0.202979 -1.729156    -0.000590    -1.717983 -1.601858   \n",
              "2           -0.890838 -1.729156     0.499431    -1.708498 -1.601858   \n",
              "3            0.009929 -1.729156     0.999452    -1.699014 -1.601858   \n",
              "4           -1.021859 -1.729156     1.499473    -1.689529 -1.601858   \n",
              "\n",
              "   temp_range  \n",
              "0    0.840131  \n",
              "1   -0.472820  \n",
              "2    0.643188  \n",
              "3    0.052360  \n",
              "4    1.584136  "
            ]
          },
          "execution_count": 283,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# print(data[features].head())\n",
        "\n",
        "# data_filled = data.fillna(-1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # Calculate the IQR\n",
        "# Q1 = data['avg_temp_c'].quantile(0.25)\n",
        "# Q3 = data['avg_temp_c'].quantile(0.75)\n",
        "# IQR = Q3 - Q1\n",
        "\n",
        "# # Define the lower and upper bounds for outliers\n",
        "# lower_bound = Q1 - 1.5 * IQR\n",
        "# upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# # Identify outliers\n",
        "# outliers = data[(data['avg_temp_c'] < lower_bound) | (data['avg_temp_c'] > upper_bound)]\n",
        "# print(\"Outliers in avg_temp_c:\")\n",
        "# print(outliers)\n",
        "# outliers.shape, data.shape\n",
        "# # Remove outliers\n",
        "# data_cleaned = data[(data['avg_temp_c'] >= lower_bound) & (data['avg_temp_c'] <= upper_bound)]\n",
        "\n",
        "# # Display the cleaned data\n",
        "# print(data_cleaned.head())\n",
        "# data  = data_cleaned "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {
        "id": "bmpLwNTnW3mt"
      },
      "outputs": [],
      "source": [
        "# Create sequences for each city\n",
        "def create_sequences(df, features, target, seq_length=15, pred_length=3):#  seq_length=30, pred_length=7\n",
        "    X = []\n",
        "    y = []\n",
        "    for i in range(len(df) - seq_length - pred_length + 1):\n",
        "        X.append(df[features].iloc[i:i+seq_length].values)\n",
        "        y.append(df[target].iloc[i+seq_length:i+seq_length+pred_length].values)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "\n",
        "# Split data by city and create sequences\n",
        "city_data = data.groupby('city_id')\n",
        "seq_length=15 #  seq_length=30\n",
        "X_list = []\n",
        "y_list = []\n",
        "X_list_final = []\n",
        "last_dates = []\n",
        "for i, (_, group) in enumerate(city_data):\n",
        "    X, y = create_sequences(group, features, target, seq_length=seq_length)\n",
        "    X_list.append(X)\n",
        "    y_list.append(y)\n",
        "    X_last = group[features].iloc[-seq_length:].values\n",
        "    X_list_final.append(X_last)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--1L3KiSW3mt",
        "outputId": "d61252e2-c152-4e90-f808-b98fb1783565"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100\n",
            "100\n",
            "1790\n",
            "1790\n",
            "[1790, 1767, 1787, 1790, 1790, 1789, 1790, 1790, 1769, 1790, 1787, 1790, 1790, 1790, 1788, 1790, 1780, 1790, 1790, 1790, 1790, 1787, 1773, 1790, 1777, 1790, 1790, 1787, 1790, 1790, 1790, 1790, 1790, 1790, 1776, 1790, 1788, 1790, 1789, 1789, 1790, 1790, 1790, 1790, 1790, 1789, 1790, 1753, 1790, 1790, 1789, 1789, 1790, 1787, 1790, 1789, 1786, 1790, 1789, 1790, 1790, 1790, 1790, 1781, 1790, 1789, 1790, 1790, 1788, 1790, 1790, 1790, 1790, 1790, 1790, 1776, 1790, 1790, 1789, 1774, 1790, 1790, 1784, 1790, 1790, 1787, 1790, 1784, 1790, 1789, 1790, 1788, 1789, 1790, 1790, 1790, 1790, 1789, 1783, 1764]\n",
            "30\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(30, 9)"
            ]
          },
          "execution_count": 286,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(len(X_list))\n",
        "print(len(y_list))\n",
        "print(len(X_list[0]))\n",
        "print(len(y_list[0]))\n",
        "lengths = [len(element) for element in X_list]\n",
        "print(lengths)\n",
        "print(len(X_list[0][0]))\n",
        "X_list[0][0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 287,
      "metadata": {
        "id": "PnTFuL0bW3mu"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 288,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VBHveosW3mu",
        "outputId": "ec41d2d2-e55b-4dea-fab5-f03fb636e1f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(178738, 30, 9)\n",
            "(100, 30, 9)\n"
          ]
        }
      ],
      "source": [
        "print(np.concatenate(X_list, axis=0).shape)\n",
        "print(np.array(X_list_final).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 289,
      "metadata": {
        "id": "JDBaBNUOIRtM"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "X = np.concatenate(X_list, axis=0)\n",
        "y = np.concatenate(y_list, axis=0)\n",
        "\n",
        "# Split into train and test sets\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     X, y, test_size=0.2)\n",
        "num_samples = X.shape[0]  # Number of samples in your dataset\n",
        "split_index = int(num_samples * (1 - 0.05))  # Calculate index for 80% of the data\n",
        "\n",
        "# Split the data at the calculated index\n",
        "X_train, X_test = X[:split_index], X[split_index:]\n",
        "y_train, y_test = y[:split_index], y[split_index:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 290,
      "metadata": {
        "id": "lueKAvApIUwL"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).to(device)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 291,
      "metadata": {
        "id": "Wc_SdQ70W3mu"
      },
      "outputs": [],
      "source": [
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 292,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NBBTxb6W3mv",
        "outputId": "ca8d255a-01e0-4c21-e884-0a319eaa7b4a"
      },
      "outputs": [],
      "source": [
        "# Convert to PyTorch tensors\n",
        "X_predict_tensor = torch.tensor(X_list_final, dtype=torch.float32).to(device)\n",
        "predict_dataset = TensorDataset(X_predict_tensor)\n",
        "predict_loader = DataLoader(predict_dataset, batch_size=1, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 293,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1yVgEQcW3mv",
        "outputId": "d2cccd31-7c0b-4996-ac0f-f8ed9e21dda4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Inputs Shape: torch.Size([32, 30, 9]), Train Targets Shape: torch.Size([32, 7])\n",
            "Test Inputs Shape: torch.Size([32, 30, 9]), Test Targets Shape: torch.Size([32, 7])\n",
            "Predict Inputs Shape: torch.Size([1, 30, 9])\n"
          ]
        }
      ],
      "source": [
        "# For the train loader\n",
        "for i, (inputs, targets) in enumerate(train_loader):\n",
        "    if i == 1:\n",
        "        break\n",
        "    print(f'Train Inputs Shape: {inputs.shape}, Train Targets Shape: {targets.shape}')\n",
        "# For the test loader\n",
        "for i, (inputs, targets) in enumerate(test_loader):\n",
        "    if i == 1:\n",
        "        break\n",
        "    print(f'Test Inputs Shape: {inputs.shape}, Test Targets Shape: {targets.shape}')\n",
        "for i, (inputs,) in enumerate(predict_loader):\n",
        "    if i == 1:\n",
        "        break\n",
        "    print(f'Predict Inputs Shape: {inputs.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 294,
      "metadata": {
        "id": "p6ULpEUEW3mw"
      },
      "outputs": [],
      "source": [
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layer_size, output_size, num_layers, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_layer_size,\n",
        "                            num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)  # Dropout layer before the fully connected layer\n",
        "        self.fc = nn.Linear(hidden_layer_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_layer_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_layer_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.dropout(out[:, -1, :])  # Apply dropout to the output of the LSTM layer\n",
        "        out = self.fc(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 295,
      "metadata": {
        "id": "O2U3rAfbW3mw"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, dataloader):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, target in dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        # Apply gradient clipping\n",
        "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 296,
      "metadata": {
        "id": "RhQ7_r69W3mw"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, criterion, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in dataloader:\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 297,
      "metadata": {
        "id": "u0-P7fVBW3mw"
      },
      "outputs": [],
      "source": [
        "def model_fit(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs=25, patience=10, checkpoint=40):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "\n",
        "    best_test_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_model(\n",
        "            model, criterion, optimizer, train_dataloader)\n",
        "        test_loss = evaluate_model(\n",
        "            model, criterion, test_dataloader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        if test_loss < best_test_loss:\n",
        "            best_test_loss = test_loss\n",
        "            patience_counter = 0\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "        if (epoch + 1) % checkpoint == 0:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    return model, train_losses, test_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 298,
      "metadata": {
        "id": "HXuaDH5PW3mx"
      },
      "outputs": [],
      "source": [
        "def plot_losses(train_losses, test_losses, figsize=(6, 3)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(train_losses, label='Train Loss')\n",
        "    plt.plot(test_losses, label='Test Loss')\n",
        "    plt.title('Losses')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 299,
      "metadata": {
        "id": "iv131aYXrVL3"
      },
      "outputs": [],
      "source": [
        "# Define model, loss function, and optimizer\n",
        "input_size = len(features)\n",
        "hidden_layer_size = 64\n",
        "output_size = 3\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "\n",
        "model = LSTMModel(input_size, hidden_layer_size,\n",
        "                  output_size, num_layers, dropout).to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 300,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6XQk6hwW3mx",
        "outputId": "04009817-fe37-4b23-c305-9d35f36d73af"
      },
      "outputs": [],
      "source": [
        "# model, train_losses, test_losses = model_fit(\n",
        "#     model, loss_function, optimizer, train_loader, test_loader, num_epochs=25, checkpoint=5, patience=10)\n",
        "# plot_losses(train_losses, test_losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 301,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\amp\\grad_scaler.py:131: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
            "  warnings.warn(\n",
            "c:\\Users\\lisit\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\amp\\autocast_mode.py:250: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25: Train Loss = 0.0984, Test Loss = 0.0586\n",
            "Epoch 2/25: Train Loss = 0.0869, Test Loss = 0.0597\n",
            "Epoch 3/25: Train Loss = 0.0853, Test Loss = 0.0593\n",
            "Epoch 4/25: Train Loss = 0.0836, Test Loss = 0.0561\n",
            "Epoch 5/25: Train Loss = 0.0831, Test Loss = 0.0543\n",
            "Epoch 6/25: Train Loss = 0.0822, Test Loss = 0.0534\n",
            "Epoch 7/25: Train Loss = 0.0812, Test Loss = 0.0533\n",
            "Epoch 8/25: Train Loss = 0.0809, Test Loss = 0.0555\n",
            "Epoch 9/25: Train Loss = 0.0801, Test Loss = 0.0524\n",
            "Epoch 10/25: Train Loss = 0.0797, Test Loss = 0.0517\n",
            "Epoch 11/25: Train Loss = 0.0790, Test Loss = 0.0511\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "import numpy as np\n",
        "\n",
        "# Define LSTM model class\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, input_size, hidden_layer_size, output_size, num_layers, dropout):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.hidden_layer_size = hidden_layer_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size, hidden_layer_size,\n",
        "                            num_layers=num_layers, dropout=dropout, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.fc = nn.Linear(hidden_layer_size, output_size)\n",
        "        \n",
        "        # Weight initialization\n",
        "        for name, param in self.lstm.named_parameters():\n",
        "            if 'weight' in name:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_layer_size).to(x.device)\n",
        "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_layer_size).to(x.device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.dropout(out[:, -1, :])\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "def train_model(model, criterion, optimizer, dataloader, scaler):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for data, target in dataloader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast():\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "        \n",
        "        scaler.scale(loss).backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def evaluate_model(model, criterion, dataloader):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in dataloader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def model_fit(model, criterion, optimizer, train_dataloader, test_dataloader, num_epochs=25, patience=10, checkpoint=5):\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    best_test_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train_model(model, criterion, optimizer, train_dataloader, scaler)\n",
        "        test_loss = evaluate_model(model, criterion, test_dataloader)\n",
        "\n",
        "        train_losses.append(train_loss)\n",
        "        test_losses.append(test_loss)\n",
        "\n",
        "        if test_loss < best_test_loss:\n",
        "            best_test_loss = test_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pth')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        scheduler.step(test_loss)\n",
        "        \n",
        "        if (epoch + 1) % checkpoint == 0:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}: Train Loss = {train_loss:.4f}, Test Loss = {test_loss:.4f}\")\n",
        "\n",
        "        if patience_counter >= patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    # Load the best model\n",
        "    model.load_state_dict(torch.load('best_model.pth'))\n",
        "\n",
        "    return model, train_losses, test_losses\n",
        "\n",
        "# Define model, loss function, and optimizer\n",
        "input_size = len(features)\n",
        "hidden_layer_size = 64\n",
        "output_size = 3\n",
        "num_layers = 2\n",
        "dropout = 0.5\n",
        "\n",
        "model = LSTMModel(input_size, hidden_layer_size, output_size, num_layers, dropout).to(device)\n",
        "loss_function = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "# Data loaders\n",
        "batch_size = 64\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "model, train_losses, test_losses = model_fit(\n",
        "    model, loss_function, optimizer, train_loader, test_loader, num_epochs=25, checkpoint=1, patience=10)\n",
        "\n",
        "# Plot losses\n",
        "plot_losses(train_losses, test_losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAE8CAYAAADe24uJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABhz0lEQVR4nO3deVxU9f748dcMO8iiomwiuKC4gqIiampJ4lJJ2s3Mm9o1vS1aRvUr+6ppG6VZ3tSyzepWpllu18xSchdTcTdFMxdUBkVll23m/P44MDqCqAicGXw/H4/zYObM55x5Hw4wbz6rTlEUBSGEEEIIG6LXOgAhhBBCiFslCYwQQgghbI4kMEIIIYSwOZLACCGEEMLmSAIjhBBCCJsjCYwQQgghbI4kMEIIIYSwOZLACCGEEMLmSAIjhBBCCJsjCYwQQgghbI4kMEKIGvXVV1+h0+nYuXOn1qEIIWyYJDBCCCGEsDmSwAghhBDC5kgCI4SwOrt376Z///54eHhQp04d+vTpw7Zt2yzKFBUVMW3aNEJCQnB2dqZ+/fr06NGDNWvWmMsYDAYef/xxGjVqhJOTE35+fgwaNIgTJ05YnOuXX37hrrvuws3NDXd3dwYOHMjBgwctytzsuYQQNcNe6wCEEOJqBw8e5K677sLDw4P/9//+Hw4ODnzyySf07t2bDRs2EBkZCcDUqVOJj4/niSeeoEuXLmRlZbFz50527drFvffeC8CQIUM4ePAg48ePJzg4mHPnzrFmzRpOnTpFcHAwAN988w0jR44kJiaGd999l7y8PD7++GN69OjB7t27zeVu5lxCiBqkCCFEDfryyy8VQNmxY0e5r8fGxiqOjo7KsWPHzPvOnj2ruLu7Kz179jTvCwsLUwYOHHjd97l06ZICKDNmzLhumezsbMXLy0sZM2aMxX6DwaB4enqa99/MuYQQNUuakIQQVsNoNPLbb78RGxtL06ZNzfv9/Px49NFH2bx5M1lZWQB4eXlx8OBBjh49Wu65XFxccHR0ZP369Vy6dKncMmvWrCEjI4Nhw4aRnp5u3uzs7IiMjGTdunU3fS4hRM2SBEYIYTXOnz9PXl4eLVu2LPNaq1atMJlMpKSkAPD666+TkZFBixYtaNeuHS+99BL79u0zl3dycuLdd9/ll19+wcfHh549ezJ9+nQMBoO5TGnyc88999CgQQOL7bfffuPcuXM3fS4hRM2SBEYIYZN69uzJsWPHmD9/Pm3btuXzzz+nY8eOfP755+YyEyZM4MiRI8THx+Ps7MzkyZNp1aoVu3fvBsBkMgFqP5g1a9aU2ZYvX37T5xJC1DCt27CEEHeWivrAFBcXK66ursrDDz9c5rUnn3xS0ev1SmZmZrnnzc7OVjp06KAEBARc972PHDmiuLq6KsOHD1cURVF++OEHBVB+/fXXW76Oa88lhKhZUgMjhLAadnZ29O3bl+XLl1sMT05LS2PBggX06NEDDw8PAC5cuGBxbJ06dWjevDkFBQUA5OXlkZ+fb1GmWbNmuLu7m8vExMTg4eHB22+/TVFRUZl4zp8/f9PnEkLULBlGLYTQxPz581m9enWZ/VOnTmXNmjX06NGDp59+Gnt7ez755BMKCgqYPn26uVzr1q3p3bs3ERER1KtXj507d/Ljjz8ybtw4AI4cOUKfPn14+OGHad26Nfb29ixdupS0tDQeeeQRADw8PPj444957LHH6NixI4888ggNGjTg1KlT/Pzzz3Tv3p05c+bc1LmEEDVM6yogIcSdpbQJ6XpbSkqKsmvXLiUmJkapU6eO4urqqtx9993K1q1bLc7z5ptvKl26dFG8vLwUFxcXJTQ0VHnrrbeUwsJCRVEUJT09XXnmmWeU0NBQxc3NTfH09FQiIyOVH374oUxM69atU2JiYhRPT0/F2dlZadasmTJq1Chl586dt3wuIUTN0CmKomiYPwkhhBBC3DLpAyOEEEIImyMJjBBCCCFsjiQwQgghhLA5ksAIIYQQwuZIAiOEEEIImyMJjBBCCCFsjuYT2c2dO5cZM2ZgMBgICwtj9uzZdOnSpdyyBw8eZMqUKSQlJXHy5Ek++OADJkyYcMvnzM/P54UXXmDhwoUUFBQQExPDRx99hI+Pz03HbTKZOHv2LO7u7uh0ulu+biGEEOJOpSgK2dnZ+Pv7o9dXsi5Fy0loFi5cqDg6Oirz589XDh48qIwZM0bx8vJS0tLSyi2/fft25cUXX1S+//57xdfXV/nggw8qdc4nn3xSCQwMVBISEpSdO3cqXbt2Vbp163ZLsaekpFQ4GZdssskmm2yyyVbxlpKSckufvVfTdCK7yMhIOnfuzJw5cwC1ViMwMJDx48fzyiuvVHhscHAwEyZMKFMDc6NzZmZm0qBBAxYsWMBDDz0EwOHDh2nVqhWJiYl07dr1pmLPzMzEy8uLlJQU89osQgghhLixrKwsAgMDycjIwNPTs1Ln0KwJqbCwkKSkJCZOnGjep9friY6OJjExsdrOmZSURFFREdHR0eYyoaGhNG7cuMIEpqCgwGLRtuzsbEBdS0USGCGEEOLW3U4XDM068aanp2M0Gsv0O/Hx8cFgMFTbOQ0GA46Ojnh5ed3S+8bHx+Pp6WneAgMDKxWjEEIIIW6fjEK6SRMnTiQzM9O8paSkaB2SEEIIccfSrAnJ29sbOzs70tLSLPanpaXh6+tbbef09fWlsLCQjIwMi1qYG72vk5MTTk5OlYpLCCGEEFVLswTG0dGRiIgIEhISiI2NBdQOtwkJCYwbN67azhkREYGDgwMJCQkMGTIEgOTkZE6dOkVUVNRtX5cQQojKMRqNFBUVaR2GqAJ2dnbY29tX6zQjms4DExcXx8iRI+nUqRNdunRh1qxZ5Obm8vjjjwMwYsQIAgICiI+PB9ROun/++af58ZkzZ9izZw916tShefPmN3VOT09PRo8eTVxcHPXq1cPDw4Px48cTFRV10yOQhBBCVK2cnBxOnz6NhgNjRRVzdXXFz88PR0fHajm/pgnM0KFDOX/+PFOmTMFgMBAeHs7q1avNnXBPnTplMcHN2bNn6dChg/n5e++9x3vvvUevXr1Yv379TZ0T4IMPPkCv1zNkyBCLieysQWGxCUd76ZokhLhzGI1GTp8+jaurKw0aNJDJQW2coigUFhZy/vx5jh8/TkhISOUnq6uApvPA2LKsrCw8PT3JzMyskmHUyYZspv3vIEaTwqJ/S1OWEOLOkZ+fz/HjxwkODsbFxUXrcEQVycvL4+TJkzRp0gRnZ2eL16riM1TzpQSEytPFgcS/L6AocOpCHo3ru2odkhBC1CipealdqqPWxeL81Xp2cdN8PZ3p0dwbgKW7z2gcjRBCCGHdJIGxIoM7BgCwZLd0ZBNCCCEqIgmMFYlp44ubox0nL+SRdPKS1uEIIYSoYcHBwcyaNUvrMGyCJDBWxNXRnv7t/AD4aZc0IwkhhLXS6XQVblOnTq3UeXfs2MHYsWNvK7bevXuXWei4NpIExsqUNiOt3HeW/CKjxtEIIYQoT2pqqnmbNWsWHh4eFvtefPFFc1lFUSguLr6p8zZo0ABXVxnEcTMkgbEyXZvUJ8DLhez8YtYeSrvxAUIIUcsoikJeYbEm2832P/T19TVvnp6e6HQ68/PDhw/j7u7OL7/8QkREBE5OTmzevJljx44xaNAgfHx8qFOnDp07d2bt2rUW5722CUmn0/H555/z4IMP4urqSkhICCtWrLit7+9PP/1EmzZtcHJyIjg4mJkzZ1q8/tFHHxESEoKzszM+Pj489NBD5td+/PFH2rVrh4uLC/Xr1yc6Oprc3NzbiqeyZBi1ldHrdTzYIYA56/5iya4z3NfeX+uQhBCiRl0uMtJ6yq+avPefr8fg6lg1H42vvPIK7733Hk2bNqVu3bqkpKQwYMAA3nrrLZycnPjvf//L/fffT3JyMo0bN77ueaZNm8b06dOZMWMGs2fPZvjw4Zw8eZJ69erdckxJSUk8/PDDTJ06laFDh7J161aefvpp6tevz6hRo9i5cyfPPvss33zzDd26dePixYts2rQJUGudhg0bxvTp03nwwQfJzs5m06ZNmg06kQTGCj3YUU1gNhw5z/nsAhq4yyKSQghha15//XXuvfde8/N69eoRFhZmfv7GG2+wdOlSVqxYUeEagKNGjWLYsGEAvP3223z44Yds376dfv363XJM77//Pn369GHy5MkAtGjRgj///JMZM2YwatQoTp06hZubG/fddx/u7u4EBQWZZ8BPTU2luLiYwYMHExQUBEC7du1uOYaqIgmMFWrWoA7hgV7sSclg+Z4zPHFXU61DEkKIGuPiYMefr8do9t5VpVOnThbPc3JymDp1Kj///LM5Gbh8+TKnTp2q8Dzt27c3P3Zzc8PDw4Nz585VKqZDhw4xaNAgi33du3dn1qxZGI1G7r33XoKCgmjatCn9+vWjX79+5uarsLAw+vTpQ7t27YiJiaFv37489NBD1K1bt1Kx3C7pA2OlhkQ0AmCJjEYSQtxhdDodro72mmxVORuwm5ubxfMXX3yRpUuX8vbbb7Np0yb27NlDu3btKCwsrPA8Dg4OZb4/JpOpyuK8mru7O7t27eL777/Hz8+PKVOmEBYWRkZGBnZ2dqxZs4ZffvmF1q1bM3v2bFq2bMnx48erJZYbkQTGSt3f3g8HOx1/pmZxKDVL63CEEELcpi1btjBq1CgefPBB2rVrh6+vLydOnKjRGFq1asWWLVvKxNWiRQvs7NTaJ3t7e6Kjo5k+fTr79u3jxIkT/P7774CaPHXv3p1p06axe/duHB0dWbp0aY1eQylpQrJSXq6O9An1YfVBA0t2neb/BrbWOiQhhBC3ISQkhCVLlnD//fej0+mYPHlytdWknD9/nj179ljs8/Pz44UXXqBz58688cYbDB06lMTERObMmcNHH30EwMqVK/n777/p2bMndevWZdWqVZhMJlq2bMkff/xBQkICffv2pWHDhvzxxx+cP3+eVq1aVcs13IjUwFix0jlhlu05S7Gxen7IhRBC1Iz333+funXr0q1bN+6//35iYmLo2LFjtbzXggUL6NChg8X22Wef0bFjR3744QcWLlxI27ZtmTJlCq+//jqjRo0CwMvLiyVLlnDPPffQqlUr5s2bx/fff0+bNm3w8PBg48aNDBgwgBYtWjBp0iRmzpxJ//79q+UabkSnyKI7lVIVS4HfSGGxia7xCVzMLeSrxzvTu2XDankfIYTQUn5+PsePH6dJkyY4OztrHY6oIhXd16r4DJUaGCvmaK/ngTB1HhhZWkAIIYS4QhIYK1fajPTbQQNZ+UUaRyOEEEJYB0lgrFy7AE9CGtahoNjEL/tTtQ5HCCGEsAqSwFg5nU7H4I7qnDDSjCSEEEKoNE9g5s6dS3BwMM7OzkRGRrJ9+/YKyy9evJjQ0FCcnZ1p164dq1atsng9LS2NUaNG4e/vj6urK/369ePo0aMWZXr37l1m6fMnn3yyyq+tqsR28Eeng+3HL5JyMU/rcIQQQgjNaZrALFq0iLi4OF577TV27dpFWFgYMTEx150ieevWrQwbNozRo0eze/duYmNjiY2N5cCBA4C6gmlsbCx///03y5cvZ/fu3QQFBZW7WuaYMWMslj6fPn16tV9vZfl5utC9mTcgM/MKIYQQoHEC8/777zNmzBgef/xxWrduzbx583B1dWX+/Pnllv/Pf/5Dv379eOmll2jVqhVvvPEGHTt2ZM6cOQAcPXqUbdu28fHHH9O5c2datmzJxx9/zOXLl/n+++8tzuXq6mqxHHp1DYWuKkMi1M68S3af1mzlTyGEEMJaaJbAFBYWkpSURHR09JVg9Hqio6NJTEws95jExESL8gAxMTHm8gUFBQAW4831ej1OTk5s3rzZ4rjvvvsOb29v2rZty8SJE8nLq7hppqCggKysLIutJsW08cXV0Y6TF/JIOnmpRt9bCCGEsDaaJTDp6ekYjUZ8fHws9vv4+GAwGMo9xmAwVFg+NDSUxo0bM3HiRC5dukRhYSHvvvsup0+fJjX1ygieRx99lG+//ZZ169YxceJEvvnmG/75z39WGG98fDyenp7mLTAwsDKXXWmujvb0b+sHSGdeIYQQQvNOvFXJwcGBJUuWcOTIEerVq4erqyvr1q2jf//+6PVXLnXs2LHExMTQrl07hg8fzn//+1+WLl3KsWPHrnvuiRMnkpmZad5SUlJq4pIslDYjrdx3lvwiY42/vxBCCGEtNEtgvL29sbOzIy0tzWJ/Wloavr6+5R7j6+t7w/IRERHs2bOHjIwMUlNTWb16NRcuXKBp06bXjSUyMhKAv/7667plnJyc8PDwsNhqWtcm9fH3dCY7v5iEQ+V3dBZCCFH9rh3Jeu02derU2zr3smXLqqxcbaVZAuPo6EhERAQJCQnmfSaTiYSEBKKioso9JioqyqI8wJo1a8ot7+npSYMGDTh69Cg7d+5k0KBB142ldMVOPz+/SlxJzdHrdTxYMjPvT7tOaxyNEELcua4exTpr1iw8PDws9r344otah1jradqEFBcXx2effcbXX3/NoUOHeOqpp8jNzeXxxx8HYMSIEUycONFc/rnnnmP16tXMnDmTw4cPM3XqVHbu3Mm4cePMZRYvXsz69evNQ6nvvfdeYmNj6du3LwDHjh3jjTfeICkpiRMnTrBixQpGjBhBz549ad++fc1+AyqhdFK7DUfOcz67QONohBCiGigKFOZqs93kKM+rR7F6enqi0+ks9i1cuJBWrVrh7OxMaGgoH330kfnYwsJCxo0bh5+fH87OzgQFBREfHw9AcHAwAA8++CA6nc78/FaZTCZef/11GjVqhJOTE+Hh4axevfqmYlAUhalTp9K4cWOcnJzw9/fn2WefrVQc1cleyzcfOnQo58+fZ8qUKRgMBvM3uLSj7qlTpyz6rnTr1o0FCxYwadIkXn31VUJCQli2bBlt27Y1l0lNTSUuLo60tDT8/PwYMWIEkydPNr/u6OjI2rVrmTVrFrm5uQQGBjJkyBAmTZpUcxd+G5o1qEN4oBd7UjJYsfcso3s00TokIYSoWkV58La/Nu/96llwdLutU3z33XdMmTKFOXPm0KFDB3bv3s2YMWNwc3Nj5MiRfPjhh6xYsYIffviBxo0bk5KSYu5XuWPHDho2bMiXX35Jv379sLOzq1QM//nPf5g5cyaffPIJHTp0YP78+TzwwAMcPHiQkJCQCmP46aef+OCDD1i4cCFt2rTBYDCwd+/e2/qeVAedIpOKVEpVLAVeWd8knmDy8oO09vNg1XN31eh7CyFEVcvPz+f48eM0adJEnQajMNemEpivvvqKCRMmkJGRAUDz5s154403GDZsmLnMm2++yapVq9i6dSvPPvssBw8eZO3ateh0ujLn0+l0LF26lNjY2Arft6JyAQEBPPPMM7z66qvmfV26dKFz587MnTu3whjef/99PvnkEw4cOICDg8PNfyOuUea+XqUqPkM1rYERlXNfe39eX/knf6ZmcSg1i1Z+1j0JnxBC3BIHVzWR0Oq9b0Nubi7Hjh1j9OjRjBkzxry/uLgYT09PAEaNGsW9995Ly5Yt6devH/fdd5+5m0NVyMrK4uzZs3Tv3t1if/fu3c01KRXF8I9//INZs2bRtGlT+vXrx4ABA7j//vuxt7eulKFWDaO+U9R1c6RPqNrMtnS3zAkjhKhldDq1FkSLrZwakVuRk5MDwGeffcaePXvM24EDB9i2bRsAHTt25Pjx47zxxhtcvnyZhx9+mIceeui2v223oqIYAgMDSU5O5qOPPsLFxYWnn36anj17UlRUVKMx3ogkMDZqcMlopKW7z1BsNGkcjRBCCFAnV/X39+fvv/+mefPmFluTJlf6LHp4eDB06FA+++wzFi1axE8//cTFixcBdU4zo7Hyc315eHjg7+/Pli1bLPZv2bKF1q1b31QMLi4u3H///Xz44YesX7+exMRE9u/fX+mYqoN11QeJm9a7ZUPqujpwPruAzX+l07tlQ61DEkIIAUybNo1nn30WT09P+vXrR0FBATt37uTSpUvExcXx/vvv4+fnR4cOHdDr9SxevBhfX1+8vLwAdSRSQkIC3bt3x8nJibp16173vY4fP26eCqRUSEgIL730Eq+99hrNmjUjPDycL7/8kj179vDdd98BVBjDV199hdFoJDIyEldXV7799ltcXFwICgqqrm9ZpUgCY6Mc7fU8EObP14knWbLrjCQwQghhJZ544glcXV2ZMWMGL730Em5ubrRr144JEyYA4O7uzvTp0zl69Ch2dnZ07tyZVatWmUfdzpw50zzNSEBAACdOnLjue8XFxZXZt2nTJp599lkyMzN54YUXOHfuHK1bt2bFihWEhITcMAYvLy/eeecd4uLiMBqNtGvXjv/973/Ur1+/yr9Xt0NGIVWSlqOQSu07ncEDc7bgZK9n56Ro3J0r31tcCCG0UtFoFWG7qnsUkvSBsWHtAjxp3rAOBcUmVu1PvfEBQgghRC0hCYwN0+l05s68skK1EEKIO4kkMDbuwQ4B6HSw/fhFUi7maR2OEEIIUSMkgbFxfp4udG/mDcASqYURQghxh5AEphYobUZasvs00idbCGGr5O9X7VLd91MSmFqgX1tfXB3tOHkhj12nLmkdjhBC3JLSBQsLCws1jkRUpbw8tVvD7aynVBGZB6YWcHW0p39bP37adZqfdp0hIqie1iEJIcRNs7e3x9XVlfPnz+Pg4GCeD0XYJkVRyMvL49y5c3h5eVV6Re0bkQSmlhjSMYCfdp1m5d6zTLmvNc4O1fMDI4QQVU2n0+Hn58fx48c5efKk1uGIKuLl5YWvr2+1nV8SmFqia9P6+Hs6czYzn4RD5xjY3k/rkIQQ4qY5OjoSEhIizUi1hIODQ7XVvJSSBKaW0Ot1PNgxgLnrjrFk12lJYIQQNkev18tMvOKmSUNjLfJgh0YArD9ynvPZBRpHI4QQQlQfSWBqkeYN6xAW6IXRpLBi71mtwxFCCCGqjSQwtcxDpXPC7DqtcSRCCCFE9dE8gZk7dy7BwcE4OzsTGRnJ9u3bKyy/ePFiQkNDcXZ2pl27dqxatcri9bS0NEaNGoW/vz+urq7069ePo0ePWpTJz8/nmWeeoX79+tSpU4chQ4aQlpZW5demhfva++Ngp+Pg2SwOG7K0DkcIIYSoFpomMIsWLSIuLo7XXnuNXbt2ERYWRkxMDOfOnSu3/NatWxk2bBijR49m9+7dxMbGEhsby4EDBwB17HlsbCx///03y5cvZ/fu3QQFBREdHU1ubq75PM8//zz/+9//WLx4MRs2bODs2bMMHjy4Rq65utV1c+Se0IaALC0ghBCi9tIpGs7dHBkZSefOnZkzZw4AJpOJwMBAxo8fzyuvvFKm/NChQ8nNzWXlypXmfV27diU8PJx58+Zx5MgRWrZsyYEDB2jTpo35nL6+vrz99ts88cQTZGZm0qBBAxYsWMBDDz0EwOHDh2nVqhWJiYl07dr1pmLPysrC09OTzMxMPDw8bvdbUaV+PWjg398k0cDdicRX7sHeTvOKNiGEEMKsKj5DNftkKywsJCkpiejo6CvB6PVER0eTmJhY7jGJiYkW5QFiYmLM5QsK1JE3Vw/D0+v1ODk5sXnzZgCSkpIoKiqyOE9oaCiNGze+7vuWnjsrK8tis1Z3t2xIXVcHzmcXsOXYBa3DEUIIIaqcZglMeno6RqMRHx8fi/0+Pj4YDIZyjzEYDBWWL01EJk6cyKVLlygsLOTdd9/l9OnTpKamms/h6OiIl5fXTb8vQHx8PJ6enuYtMDDwVi+5xjja63kgzB+An5KkM68QQojap1a1LTg4OLBkyRKOHDlCvXr1cHV1Zd26dfTv3/+219aYOHEimZmZ5i0lJaWKoq4egzuqc8L8etBAdn6RxtEIIYQQVUuzBMbb2xs7O7syo3/S0tKuu3aCr6/vDctHRESwZ88eMjIySE1NZfXq1Vy4cIGmTZuaz1FYWEhGRsZNvy+Ak5MTHh4eFps1a9/Ik+YN61BQbOKX/devWRJCCCFskWYJjKOjIxERESQkJJj3mUwmEhISiIqKKveYqKgoi/IAa9asKbe8p6cnDRo04OjRo+zcuZNBgwYBaoLj4OBgcZ7k5GROnTp13fe1RTqdjsElc8L8KHPCCCGEqGU0XQspLi6OkSNH0qlTJ7p06cKsWbPIzc3l8ccfB2DEiBEEBAQQHx8PwHPPPUevXr2YOXMmAwcOZOHChezcuZNPP/3UfM7FixfToEEDGjduzP79+3nuueeIjY2lb9++gJrYjB49mri4OOrVq4eHhwfjx48nKirqpkcg2YrY8ABm/JrM9uMXSbmYR2A9V61DEkIIIaqEpgnM0KFDOX/+PFOmTMFgMBAeHs7q1avNHXVPnTpl0XelW7duLFiwgEmTJvHqq68SEhLCsmXLaNu2rblMamoqcXFxpKWl4efnx4gRI5g8ebLF+37wwQfo9XqGDBlCQUEBMTExfPTRRzVz0TXI38uFbs3qs+WvCyzdfYZn+4RoHZIQQghRJTSdB8aWWfM8MFdbsus0cT/sJbi+K+te7I1Op9M6JCGEEHc4m54HRtSMmDa+uDraceJCHrtOXdI6HCGEEKJKSAJTy7k52dOvrTq66idZWkAIIUQtIQnMHeChkjlhVu49S36RUeNohBBCiNsnCcwdoGvT+vh7OpOVX0zCofIXyhRCCCFsiSQwdwC9XkdsB3VOmCUyJ4wQQohaQBKYO0Tp0gLrj5wnPadA42iEEEKI2yMJzB2iecM6hAV6YTQpLN9zVutwhBBCiNsiCcwdZEjJ0gLv/HKIF37YS7IhW+OIhBBCiMqRBOYO8lBEI3q1aECRUeGnXaeJmbWRUV9uZ+uxdGQ+QyGEELZEZuKtJFuZibc8u09d4rNNf7P6gAFTyd1v38iTsT2b0q+NL/Z2ktcKIYSoPlXxGSoJTCXZcgJT6kR6Lp9v/pvFO09TUGwCILCeC0/0aMo/OjXC1VHTpbKEEELUUpLAaKg2JDClLuQU8N/Ek/w38QSX8ooAqOvqwGNRwYyMCqJ+HSeNIxRCCFGbSAKjodqUwJS6XGhkcVIKn286zqmLeQA42et5KKIRY+5qSrC3m8YRCiGEqA0kgdFQbUxgShlNCqsPGPh04zH2ns4EQKeDmNa+/LtXUzo0rqtxhEIIIWyZJDAaqs0JTClFUfjj+EU+3fg3vx++sgRBl+B6jO3ZlHtCG6LX6zSMUAghhC2SBEZDd0ICc7Ujadl8uvFvlu85Q5FR/ZFp3rAOY+9qyqAO/jjZ22kcoRBCCFshCYyG7rQEppQhM58vtx5nwbZTZBcUA9DQ3YlR3YMZHhmEp4uDxhEKIYSwdpLAaOhOTWBKZecXsXB7Cl9sPo4hKx8AN0c7hnVpzL96NMHfy0XjCIUQQlgrSWA0dKcnMKUKi038b+9ZPt34N8lp6tIE9nodd4c2ZFC4P31CfXBxlOYlIYQQV1TFZ6jmU67OnTuX4OBgnJ2diYyMZPv27RWWX7x4MaGhoTg7O9OuXTtWrVpl8XpOTg7jxo2jUaNGuLi40Lp1a+bNm2dRpnfv3uh0OovtySefrPJruxM42usZEtGI1RPu4qvHO9OtWX2KTQpr/kxj3ILddHpzDXGL9rAu+RxFRpPW4QohhKglNJ1qddGiRcTFxTFv3jwiIyOZNWsWMTExJCcn07BhwzLlt27dyrBhw4iPj+e+++5jwYIFxMbGsmvXLtq2bQtAXFwcv//+O99++y3BwcH89ttvPP300/j7+/PAAw+YzzVmzBhef/1183NXV9fqv+BaTKfT0btlQ3q3bMiRtGyW7znD8j1nOX3pMkt2n2HJ7jPUc3NkYDs/BoX707FxXRnBJIQQotI0bUKKjIykc+fOzJkzBwCTyURgYCDjx4/nlVdeKVN+6NCh5ObmsnLlSvO+rl27Eh4ebq5ladu2LUOHDmXy5MnmMhEREfTv358333wTUGtgwsPDmTVr1k3HWlBQQEFBgfl5VlYWgYGBd3wTUkUURWHXqQxW7DnDyn2pXMgtNL8W4OXCA+H+DAr3J9RXvn9CCHEnsekmpMLCQpKSkoiOjr4SjF5PdHQ0iYmJ5R6TmJhoUR4gJibGony3bt1YsWIFZ86cQVEU1q1bx5EjR+jbt6/Fcd999x3e3t60bduWiRMnkpeXV2G88fHxeHp6mrfAwMBbveQ7jk6nIyKoLtMGteWPV/vw9b+6MLhjAHWc7DmTcZmP1x+j36xN9P1gA3PX/UXKxYrvgRBCCFFKsyak9PR0jEYjPj4+Fvt9fHw4fPhwuccYDIZyyxsMBvPz2bNnM3bsWBo1aoS9vT16vZ7PPvuMnj17mss8+uijBAUF4e/vz759+3j55ZdJTk5myZIl14134sSJxMXFmZ+X1sCIm2Nvp6dXiwb0atGA/CIjvx8+x/I9Z1h3+DxH0nKY8WsyM35NpmNjLwaFBzCgnR8N3GUNJiGEEOWrdcsNz549m23btrFixQqCgoLYuHEjzzzzDP7+/ubam7Fjx5rLt2vXDj8/P/r06cOxY8do1qxZued1cnLCyUk+UKuCs4MdA9r5MaCdH5mXi/j1gIHle8+QeOwCu05lsOtUBq+v/JNuzeozKDyAmDY+uDvL/DJCCCGu0CyB8fb2xs7OjrS0NIv9aWlp+Pr6lnuMr69vheUvX77Mq6++ytKlSxk4cCAA7du3Z8+ePbz33ntlmp9KRUZGAvDXX39dN4ER1cPTxYGHOwfycOdAzmXls3JfKsv3nmVvSgabjqaz6Wg6ry7VE92qIQ+EBdC7ZQOcHWRYthBC3Ok06wPj6OhIREQECQkJ5n0mk4mEhASioqLKPSYqKsqiPMCaNWvM5YuKiigqKkKvt7wsOzs7TKbrD+Hds2cPAH5+fpW5FFFFGno4868eTVj+THfWv9ibuHtb0KyBG4XFJlbtN/Dkt0l0fnMtLy3ey8Yj58kpmQlYCCHEnUfTJqS4uDhGjhxJp06d6NKlC7NmzSI3N5fHH38cgBEjRhAQEEB8fDwAzz33HL169WLmzJkMHDiQhQsXsnPnTj799FMAPDw86NWrFy+99BIuLi4EBQWxYcMG/vvf//L+++8DcOzYMRYsWMCAAQOoX78++/bt4/nnn6dnz560b99em2+EKCPY241n+4Qw/p7m/JmaxYo9Z1mx9yypmfksTjrN4qTTgDqaqYVPHVr4utOioTstfd1p3rCO1NIIIUQtp/lMvHPmzGHGjBkYDAbCw8P58MMPzU06vXv3Jjg4mK+++spcfvHixUyaNIkTJ04QEhLC9OnTGTBggPl1g8HAxIkT+e2337h48SJBQUGMHTuW559/Hp1OR0pKCv/85z85cOAAubm5BAYG8uCDDzJp0qRbGsolM/HWPJNJYceJiyzfe5aEQ2mkZRWUW06ng6B6roT4uNPSx50Qnzq09HWnqXcdHO01n7tRCCHueLKUgIYkgdFeRl4hR9JySE7L5mhaNsmGbI6kZXMpr6jc8nZ6HU283dQaGx938xZc3xV7O0lshBCipkgCoyFJYKyToiik5xSqCU1aNkfScjiSls0RQ7Z59exrOdrpadrAjZa+7lclNnUIrOsqswULIUQ1kARGQ5LA2BZFUTBk5ZNsyOboVbU2R9JyuFxkLPcYFwc7Wvi608rXnVBfd1r5eRDq64GnqwzpFkKI2yEJjIYkgakdTCaF05cuc6Skxkatucnh2PkcCovLH7nm7+msJjN+7oT6etDKz53g+m7SDCWEEDdJEhgNSQJTuxUbTZy4kMdhQxaHU7M5bMjiUGo2ZzIul1veyV5PC5+ramr83Gnl60FdN8cajlwIIayfZglMSkoKOp2ORo0aAbB9+3YWLFhA69atLWa5rc0kgbkzZV4uItlwJaE5lJpFsiH7us1QPh5O5qanViU1Nk0buOEgtTVCiDuYZgnMXXfdxdixY3nssccwGAy0bNmSNm3acPToUcaPH8+UKVMqFYwtkQRGlDKZFE5dVGtr/kzN5nBqFocN2Zy6zuKUjnZ6mjesQ6ifO639POgcXI/W/h6S1Agh7hiaJTB169Zl27ZttGzZkg8//JBFixaxZcsWfvvtN5588kn+/vvvSgVjSySBETeSU1BMcklNzZWmqOxyZxB2dbSjQ2MvOgfXo0twPTo0rouLo0zGJ4SonariM7RSM/EWFRWZFzZcu3YtDzzwAAChoaGkpqZWKhAhaps6TvZEBNUjIqieeZ+iqJ2GD5XU0uxNyWDnyUtkXi5iy18X2PLXBQDs9TraBnjSObgunYPr0Tm4nvSnEUKIq1SqBiYyMpK7776bgQMH0rdvX7Zt20ZYWBjbtm3joYce4vTp09URq1WRGhhRVUwmhaPncth+4iI7jl9kx4mLpGbmlykX0rAOnZuoNTSdm9QjwMtFg2iFEOL2adaEtH79eh588EGysrIYOXIk8+fPB+DVV1/l8OHDLFmypFLB2BJJYER1Ka2l2XnyItuPX2LHiYv8dS6nTDl/T2c6N1FrZ7o0qUfzBnVk4j0hhE3QdBi10WgkKyuLunXrmvedOHECV1dXGjZsWKlgbIkkMKImXcwtZMeJi+w8cZHtJy5x4EwmRpPlr66XqwOdgurRpUldOgXXo12Ap3QMFkJYJc0SmMuXL6MoCq6urgCcPHmSpUuX0qpVK2JiYioViK2RBEZoKa+wmN2nMthe0uS0+1RGmaHczg56OgTWpVNwXcIaeREW6EUDdyeNIhZCiCs0S2D69u3L4MGDefLJJ8nIyCA0NBQHBwfS09N5//33eeqppyoVjC2RBEZYkyKjiYNns9hx/CLbS2pqylvUMsDLhfaNPAkL9KJ9I0/aBXji7ixLIwghapZmCYy3tzcbNmygTZs2fP7558yePZvdu3fz008/MWXKFA4dOlSpYGyJJDDCmplMCsfOqx2Dd5/KYN/pDI6ey+Ha33adDpo3qEP7Rl6EB3rSvpEXoX7uONnLEG4hRPXRbBh1Xl4e7u7uAPz2228MHjwYvV5P165dOXnyZKUCEUJUHb1eR4iPOyE+7gyPDALUeWkOnMlkb0oGe09nsDclkzMZlzl6Loej53L4aZc6etDRTk8rP3fCAr1Kmp48aeotHYSFENalUglM8+bNWbZsGQ8++CC//vorzz//PADnzp2T2gghrFQdJ3u6Nq1P16b1zfvScwrYdzqDPSmZ7Dudwd6UDC7lFbH3dCZ7T2cC6j8k7k72tA3wLElq1K9+ns7odJLUCCG0UakmpB9//JFHH30Uo9HIPffcw5o1awCIj49n48aN/PLLL1UeqLWRJiRRGymKQsrFyyU1NBnsO53J/jOZ5a711MDdSU1mGnkR7O2Gq6Mdro72uDra4eZkh4ujPa4Odrg62eFop5dkRwhhpukwaoPBQGpqKmFhYej16lDN7du34+HhQWhoaKWCsSWSwIg7RbHRxNFzORY1NYcN2WWGcVfETq8rSXDscHO0x+Xqr052uDjYlyQ9drhe9fjasqXncHEoKetoj500bQlhczRNYEqVzrpbujL1rZo7dy4zZszAYDAQFhbG7Nmz6dKly3XLL168mMmTJ3PixAlCQkJ49913GTBggPn1nJwcXnnlFZYtW8aFCxdo0qQJzz77LE8++aS5TH5+Pi+88AILFy6koKCAmJgYPvroI3x8fG46bklgxJ0sv8jIwbNZ5v40aVn55BUa1a2gmLwiI3kFRgqNpmqPxdFeryY2VyU1LmUSnZL9DlclQSW1RaVl3Bztad6wjqxBJUQN0KwTr8lk4s0332TmzJnk5KgzhLq7u/PCCy/wf//3f+YamRtZtGgRcXFxzJs3j8jISGbNmkVMTAzJycnlToa3detWhg0bRnx8PPfddx8LFiwgNjaWXbt20bZtWwDi4uL4/fff+fbbbwkODua3337j6aefxt/f37xm0/PPP8/PP//M4sWL8fT0ZNy4cQwePJgtW7ZU5tshxB3H2cGOiKC6RATVrbBckdFEXqGRy4VG8gqLzUlObmExlwuN5BYUc7nISG6BkcuFxeSWvF76+HJJ2bwCI3lFxVwuNHG5UE2QSv/1Kiw2UVhsIoOyw8Zv/br09GjegL6tfbinVUO868i8OUJYq0rVwEycOJEvvviCadOm0b17dwA2b97M1KlTGTNmDG+99dZNnScyMpLOnTszZ84cQE2MAgMDGT9+PK+88kqZ8kOHDiU3N5eVK1ea93Xt2pXw8HDmzZsHQNu2bRk6dCiTJ082l4mIiKB///68+eabZGZm0qBBAxYsWMBDDz0EwOHDh2nVqhWJiYl07dr1pmKXGhghtKMoCgXFppKEqLgkQTJyuchofpxXqCZHeVclRaXPzeUL1cQor9BIZl4RF3ILze+h00HHxnWJbuXDva19aN6wjoZXLETtolkNzNdff83nn39urtEAaN++PQEBATz99NM3lcAUFhaSlJTExIkTzfv0ej3R0dEkJiaWe0xiYiJxcXEW+2JiYli2bJn5ebdu3VixYgX/+te/8Pf3Z/369Rw5coQPPvgAgKSkJIqKioiOjjYfExoaSuPGjStMYAoKCigoKDA/z8rKuuE1CiGqh06nw9nBDmcHO+pV0SrdiqJwKDWbNX+msfZQGvvPZJJ08hJJJy/x7urDNPV2I7q1msx0bFxX+t4IobFKJTAXL14st6NuaGgoFy9evKlzpKenYzQay/Q78fHx4fDhw+UeYzAYyi1vMBjMz2fPns3YsWNp1KgR9vb26PV6PvvsM3r27Gk+h6OjI15eXhWe51rx8fFMmzbtpq5NCGF7dDodrf09aO3vwXPRIaRmXmbtoXOs+TONxGPp/J2ey6cb/+bTjX9Tz82Re0Ibcm9rH+4K8cbVsVJ/SoUQt6FSv3VhYWHMmTOHDz/80GL/nDlzaN++fZUEVlmzZ89m27ZtrFixgqCgIDZu3MgzzzyDv7+/Ra3LrZo4caJF7U9WVhaBgYFVEbIQwgr5ebrwWNcgHusaRHZ+ERuPpLPmTwO/Hz7HxdxCfkw6zY9Jp3Gy19OjuTfRrX3o06ohDd2dtQ5diDtCpRKY6dOnM3DgQNauXUtUVBSgNu+kpKSwatWqmzqHt7c3dnZ2pKWlWexPS0vD19e33GN8fX0rLH/58mVeffVVli5dysCBAwG1aWvPnj289957REdH4+vrS2FhIRkZGRa1MBW9L4CTkxNOTtKhT4g7kbuzAwPb+zGwvR9FRhM7Tlxk7Z/nWHPIQMrFyyQcPkfC4XPodBAe6EV0Kx/6lvSbqYn5b0wmhZzCYjLziigoNhFc3xV7WYlc1HKVSmB69erFkSNHmDt3rrm5Z/DgwYwdO5Y333yTu+6664bncHR0JCIigoSEBGJjYwG1E29CQgLjxo0r95ioqCgSEhKYMGGCed+aNWvMSVRRURFFRUVlRkHZ2dlhMqnDOSMiInBwcCAhIYEhQ4YAkJyczKlTp8znEUKI63Gw09OtmTfdmnkz+b5WJKdls/bPNNYcOsfelAx2n1K3Gb8mE1TflXtLOgFHBNWtMKkoMprIzi8m83KRecu65nFWftE1r6vls/OLuHpaHhcHO8IDvdSRYsF16RhYF09XWbRT1C63PQ/M1fbu3UvHjh0xGsvO2lmeRYsWMXLkSD755BO6dOnCrFmz+OGHHzh8+DA+Pj6MGDGCgIAA4uPjAXUYda9evXjnnXcYOHAgCxcu5O2337YYRt27d2/S09OZM2cOQUFBbNiwgaeeespileynnnqKVatW8dVXX+Hh4cH48ePN579ZMgpJCHGttKx81h5KY+2faWw5doHC4ivz4NR1deCukAY42ustk5KSx7mFN/d3syJO9nr0Ol25Mye38KlTMvS9HhFBdQmu7yqzIwvNaDYKqaoMHTqU8+fPM2XKFAwGA+Hh4axevdrcUffUqVMWtSndunVjwYIFTJo0iVdffZWQkBCWLVtmTl4AFi5cyMSJExk+fDgXL14kKCiIt956y2Iiuw8++AC9Xs+QIUMsJrITQojb4ePhzPDIIIZHBpFbUMymo+f57c80fj98jkt5RazYe/aG56jjZI+niwMeLg54OKuPS597XrV5uFz1mrP6urODHSaTwtFzOeYRVEknL3LiQh5H0nI4kpbD99tTAKjv5kjHoLp0KpnPp22AJ84OMomfsB2a1sDYMqmBEULcrGKjiaSTl/jj+EXs7XSWiYjzlcfuzvbV0nclPaeApJOX2FWS1Ow7nVlmlmRHOz1tAzwsamkauEu/P1E9rGIpgatJAiOEENavoNjIgTNZJJ28aK6pSc8pLFMuqL4rEY3VfjQRQXVp0dAdvcx/I6pAjTchDR48uMLXMzIyKhWEEEKImuNkb7kUhKIonLqYR9LJS+wsqalJTsvm5IU8Tl7IY8nuMwC4O9vToXFd2gV44OZkj7O9HU4Oeouvzg5l91391cleViYXVeOWEhhPT88bvj5ixIjbCkgIIUTN0ul0BNV3I6i+G4M7qgvzZuUXsftUhrkfze5TGWTnF7PxyHk2Hjl/W+/nZK8mMuUlO84OdjjZ62lU14Un7mpKYD3XqrhEUQtVaRPSnUSakIQQd5Jio4nDhmx2nbrE0bQc8ouM5BebKCj5ml9kpKDkecFVz/OLjOQXGS2Ged8sBzsd/+waxLi7m1NfFtasVayuD8ydRBIYIYS4OYqiUGxSLJKaK8mNiYJiIwUlX/OLTFwuMrJqfyqbjqYD6sisf/dsyui7msiyDbWEJDAakgRGCCGq1+aj6by7+jD7z2QC4F3HieeiQ3ikcyAOMtOwTZMERkOSwAghRPUzmRR+3p/Ke78lc/JCHgDB9V15MaYlA9v5SYdgGyUJjIYkgRFCiJpTWGxi0Y5T/CfhqHnId/tGnrzSL5Ruzb01jk7cKklgNCQJjBBC1LzcgmI+33ScTzceMy+/cFeINy/3C6VtQMUjZYX1kARGQ5LACCGEdtJzCpjz+19898dJiozqx9igcH9euLcljevL0GtrJwmMhiSBEUII7Z26kMfMNcks36OuM+Vgp2N4ZBDj75Gh19ZMEhgNSQIjhBDW48CZTKb/mmyeZM/N0Y6xPZvxxF1NcHOSodfWRhIYDUkCI4QQ1mfrX+m8s/ow+06XDr125Nk+ITzSuTGO9jL02lpIAqMhSWCEEMI6KYrCqv0GZvx6mBMlQ6+D6rvyYl916LUsSKk9SWA0JAmMEEJYtyKjiYU7UvjP2qOk5xQA0C7Ak1f6h9Jdhl5rShIYDUkCI4QQtiG3oJj5m4/zyca/ySkoBtSh1//u2YwWvnVoUMdJJsSrYZLAaEgSGCGEsC0XcgqYu+4Y32w7YR56DepaS8HergTXd6OptxvB3m40Kdm8XB01jLj2kgRGQ5LACCGEbUq5mMeHCUfZdvwCZy5drnClbC9XBzWZqW+Z2AR7u1FHRjdVmiQwGpIERgghbF9BsZGUi3kcT8/jRHouf6fnciI9l+PpuRiy8is8toG7E03qX0lomni70sS7DkH1XXF2sKuhK7BNVfEZahXp49y5c5kxYwYGg4GwsDBmz55Nly5drlt+8eLFTJ48mRMnThASEsK7777LgAEDzK9fry1z+vTpvPTSSwAEBwdz8uRJi9fj4+N55ZVXquCKhBBC2AInezuaN3SneUP3Mq/lFRZzIj2PExfUhOb4VcnNhdxCzmcXcD67gO0nLlocp9OBn4czTRq4Uc/NCXu9Tt3sdNjr9SVfddjb6XHQ67Ar2edgpz5Wv+pwKNlvp9fhYKcv5xxXzmWnV5/b6a96bned/SVfbb3fj+YJzKJFi4iLi2PevHlERkYya9YsYmJiSE5OpmHDhmXKb926lWHDhhEfH899993HggULiI2NZdeuXbRt2xaA1NRUi2N++eUXRo8ezZAhQyz2v/7664wZM8b83N297A+wEEKIO5Oroz2t/T1o7V+2hiDzchEn0nM5cSGXv8+rX0trcLLzizmbmc/ZzIprcLSm12GZ3FSQDHVv7s3UB9poHbIFzZuQIiMj6dy5M3PmzAHAZDIRGBjI+PHjy60NGTp0KLm5uaxcudK8r2vXroSHhzNv3rxy3yM2Npbs7GwSEhLM+4KDg5kwYQITJkyoVNzShCSEEOJaiqJwMbfQXGOTnV+M0aRQZDJRbFQoNikUG03qPqNCsclk3md+/aqyRSVli68qW2RUMJaUKTKZMJmg2FRSzqRgLDnWWHKuivr43KyYNj588lin2z9RCZtvQiosLCQpKYmJEyea9+n1eqKjo0lMTCz3mMTEROLi4iz2xcTEsGzZsnLLp6Wl8fPPP/P111+Xee2dd97hjTfeoHHjxjz66KM8//zz2NuX/y0pKCigoKDA/DwrK+tGlyeEEOIOo9PpqF/Hifp1nOgUXE/rcAAwmRSMinJNgnNVwmNSLB5f+1qxUcHL1UHryyhD0wQmPT0do9GIj4+PxX4fHx8OHz5c7jEGg6Hc8gaDodzyX3/9Ne7u7gwePNhi/7PPPkvHjh2pV68eW7duZeLEiaSmpvL++++Xe574+HimTZt2s5cmhBBCWAW9XoceHbWtX7HmfWCq2/z58xk+fDjOzs4W+6+uxWnfvj2Ojo78+9//Jj4+HiensiuYTpw40eKYrKwsAgMDqy9wIYQQQlyXpgmMt7c3dnZ2pKWlWexPS0vD19e33GN8fX1vuvymTZtITk5m0aJFN4wlMjKS4uJiTpw4QcuWLcu87uTkVG5iI4QQQoiap+nSnI6OjkRERFh0rjWZTCQkJBAVFVXuMVFRURblAdasWVNu+S+++IKIiAjCwsJuGMuePXvQ6/XljnwSQgghhHXRvAkpLi6OkSNH0qlTJ7p06cKsWbPIzc3l8ccfB2DEiBEEBAQQHx8PwHPPPUevXr2YOXMmAwcOZOHChezcuZNPP/3U4rxZWVksXryYmTNnlnnPxMRE/vjjD+6++27c3d1JTEzk+eef55///Cd169at/osWQgghxG3RPIEZOnQo58+fZ8qUKRgMBsLDw1m9erW5o+6pU6fQ669UFHXr1o0FCxYwadIkXn31VUJCQli2bJl5DphSCxcuRFEUhg0bVuY9nZycWLhwIVOnTqWgoIAmTZrw/PPPlxndJIQQQgjrpPk8MLZK5oERQgghKqcqPkM17QMjhBBCCFEZksAIIYQQwuZIAiOEEEIImyMJjBBCCCFsjiQwQgghhLA5ksAIIYQQwuZIAiOEEEIImyMJjBBCCCFsjiQw1qa4QOsIhBBCCKsnCYy1SD8K3z0MP4zUOhIhhBDC6mm+FpK4yl9rQDHBmSQIiNA6GiGEEMJqSQ2MtfAOgfaPqI/XxWsbixBCCGHlJIGxJr1eAp2dWhOTsl3raIQQQgirJQmMNanXFMIfVR+ve1vbWIQQQggrJgmMten5Eujt4e91cHKr1tEIIYQQVkkSGGtTNwg6PKY+lloYIYQQolySwFiju14AO0c4sQmOb9Q6GiGEEMLqSAJjjbwCoWPJfDDr4kFRtI1HCCGEsDKSwFiru+LAzglObVX7wwghhBDCzCoSmLlz5xIcHIyzszORkZFs317xEOLFixcTGhqKs7Mz7dq1Y9WqVRav63S6crcZM2aYy1y8eJHhw4fj4eGBl5cXo0ePJicnp1qur1I8/KHTv9TH696WWhghhBDiKponMIsWLSIuLo7XXnuNXbt2ERYWRkxMDOfOnSu3/NatWxk2bBijR49m9+7dxMbGEhsby4EDB8xlUlNTLbb58+ej0+kYMmSIuczw4cM5ePAga9asYeXKlWzcuJGxY8dW+/Xekh7Pg70LnN4Bf63VOhohhBDCaugURdt/7SMjI+ncuTNz5swBwGQyERgYyPjx43nllVfKlB86dCi5ubmsXLnSvK9r166Eh4czb968ct8jNjaW7OxsEhISADh06BCtW7dmx44ddOrUCYDVq1czYMAATp8+jb+//w3jzsrKwtPTk8zMTDw8PG75um/ar/8HiXPAvwOMWQc6XfW9lxBCCFEDquIzVNMamMLCQpKSkoiOjjbv0+v1REdHk5iYWO4xiYmJFuUBYmJirls+LS2Nn3/+mdGjR1ucw8vLy5y8AERHR6PX6/njjz/KPU9BQQFZWVkWW43oPgEc3ODsbjiyumbeUwghhLBymiYw6enpGI1GfHx8LPb7+PhgMBjKPcZgMNxS+a+//hp3d3cGDx5scY6GDRtalLO3t6devXrXPU98fDyenp7mLTAw8IbXVyXqNIDIkqatdW9JXxghhBACK+gDU93mz5/P8OHDcXZ2vq3zTJw4kczMTPOWkpJSRRHehG7PgmMdMOyHwytvXF4IIYSo5TRNYLy9vbGzsyMtLc1if1paGr6+vuUe4+vre9PlN23aRHJyMk888USZc1zbSbi4uJiLFy9e932dnJzw8PCw2GqMaz3o+pT6eF08mEw1995CCCGEFdI0gXF0dCQiIsLcuRbUTrwJCQlERUWVe0xUVJRFeYA1a9aUW/6LL74gIiKCsLCwMufIyMggKSnJvO/333/HZDIRGRl5O5dUfaKeAScPOHcQDi3XOhohhBBCU5o3IcXFxfHZZ5/x9ddfc+jQIZ566ilyc3N5/PHHARgxYgQTJ040l3/uuedYvXo1M2fO5PDhw0ydOpWdO3cybtw4i/NmZWWxePHiMrUvAK1ataJfv36MGTOG7du3s2XLFsaNG8cjjzxyUyOQNOFSV01iANa/AyajtvEIIYQQGtI8gRk6dCjvvfceU6ZMITw8nD179rB69WpzR91Tp06RmppqLt+tWzcWLFjAp59+SlhYGD/++CPLli2jbdu2FudduHAhiqIwbNiwct/3u+++IzQ0lD59+jBgwAB69OjBp59+Wn0XWhW6PgXOnnD+MBxcqnU0QgghhGY0nwfGVtXYPDDX2jgDfn8T6jeHp/8AO/uae28hhBCiCtj8PDCiEiKfVJuTLvwF+xdrHY0QQgihCUlgbI2TO3R/Tn284V0wFmkbjxBCCKEBSWBsUecx4OoNl47D3oVaR1M7nfoDfpsEl05qHYkQQohySAJji5zqQI8J6uON06G4UNNwahVFge2fwVcDYOts+OQuOCSTBwohhLWRBMZWdRoNdXwg4xTs+U7raGqH4gL437Ow6kUwFYNbA8jPhEXD4ZeX1deFEEJYBUlgbJWjK/SIUx9vfE8+XG9XtgG+vh92/RfQQfQ0eP5PiCqZX+iPefBFX7j4t6ZhCiGEUEkCY8siRoG7H2SdLvngFZVyOgk+7Q0pf4CTJwz/UW2is3eEmLdg2CJ15FfqHvikl8zBI4QQVkASGFvm4Ax3vaA+3jQTivK1jccW7VkAX/aH7FTwbglj10FItGWZlv3gyc0Q2BUKsmDxKFgZJ99vIYTQkCQwtq7jCPBopH4AJ32ldTS2w1gMqyfCsqfAWAAtB8ATa6F+s/LLezaCUSuvNNvt/AI+j4b0v2ouZiGEEGaSwNg6eyfo+aL6ePP7UJinbTy2IO8ifDsYtn2kPu/1Mgz9DpxvMBuknQNEvwb//Ekdxp62Hz7tBftkQkEhhKhpksDUBuHDwasx5KTBzvlaR2PdDAfU/i7HN4CDGzz8Ddz9Kuhv4VehebTapBR8FxTmwJInYPk4SR6FEKIGSQJTG9g7Qs//pz7e/AEU5mobj7U6uAy+uBcyTkLdYHhiDbR+oHLn8vCDEcvV2ht0sPsb+LwPnE+uwoCFEEJcjyzmWEmaLeZ4PcYimNNZnZ03etqVie4EmEyw7i3Y9J76vGlveOhLcK1XNef/ewP89ATkngMHVxg4E8IfrZpzC3EnyM9Sk//zh+DcYfVrcSE0joSg7hAYqU7gaUuMRXDuT7Vm1sndcrNz0Do6zVXFZ6gkMJVkdQkMwJ7vYdmT4FIPJuxTf1HudPmZsGQsHFmtPo8apyZ4Vb2Kd845WDIG/l6vPg8bBgPes70/ukJUp4JsNVE5dwjOH1a3c4fVqSAqorcH/44Q3B2Ce6gjAq3tdyvvIpzeoU7HkLIdziRB0XWale1d1PjNSY1H2STn6v2O1ynr4AI6Xc1eZxWRBEZDVpnAGIvho0h1pep7JkHPl7SOSFvpf8HCYZB+BOyc4IEPIeyR6ns/k1HtSL3ubVBM4N0C/vEV+LSpvvcUwhoV5l5JTsy1KochM+X6x9TxhYah0KCV+lWnh5Nb4cTmssfp7MC/g5rMBN+l1tTU5D9sJhNcOFqSrJQkLOlHypZz9lQ7/Bdkq/3lrpfQVJbOTr3uoO7Q9Un1e2EjCY0kMBqyygQG1BExS55Qf3Em7Fe/3omO/KY26xRkgkcADP0WAjrWzHuf2AI/jVaHtts7Q//p6nB3G/nDIsRNK8yD9ORrEpVD6hIn1+PW0DJRadAKGrSsuEn30kk1kTm5BU5sKnt+nR34h6sJTVAPaNz1xqMKb0VBDpzddSVZSdkO+Rlly3m3gMAuapNXYCTUD7EcIGAshsJsNaGx2LJuYl+O5WuU89Ht0xYin4R2/1DnCbNiksBoyGoTGJMRPu6m/rfTeyL0fkXriGqWoqgdmRNeBxS1qnnoN1CnYc3GkZsOS/8Nf61Vn7d9CO6fJc16wnaZjGDYpzaTpmxX+3dcOkm5H6Sg1jw0bAUNQq9KWFpVTd+zjFPqPwonNpckNNesGq/Tg194SQ1NaUJzk//MKYpa45Oy/UoNi+EAKEbLcvYu0KjTlYSlUeeq61d3IyaTWptTkK3+o7TnO3VSztIaHldv6PQv6Dwa3H1rJqZbJAmMhqw2gQF1qvvFo9S20gn71Gnw7wSFuepw5oNL1OcRj6u1H/aO2sRjMsHWD9VkSjFCvaZqk5JfmDbxCHErFEVd++vv9ep2YhNcvlS2nGv9q2pTSraGrcDNu+ZizUi5UjtzYjNcOmH5uk6v/t4FdS9pcuoKLl7qa8WFamJ2dXNQdmrZ9/AMvKp2pYta22FNnXEvX1KXlNn+2ZUmN70DtB2iNi/5d9A2vmtIAqMhq05gTCaY1wPOHVT7wdwzSeuIqt+lk7BwuDq5nN4eBsxQ/wOxBqf+gB//pXZUtHOEmLeh8xPSpCSsT855dY6kv9ero+syr2mqcfJQE4DgHuDbVk1c6jTQJNQKZZ4uqaHZpCY2ZRZh1YFfe7UW5exudTbuq+nt1YSnNFlp1AU8A2os/NtiLIbDK2Hbx5Cy7cr+xlHQ9SloObDqBzFUQq1IYObOncuMGTMwGAyEhYUxe/ZsunTpct3yixcvZvLkyZw4cYKQkBDeffddBgwYYFHm0KFDvPzyy2zYsIHi4mJat27NTz/9ROPGjQHo3bs3GzZssDjm3//+N/PmzbvpuK06gQE49D9Y9E+19/qE/TVXtamF45tg8UjIuwBuDdTJ6YKitI7KUt5FWP4MJK9Sn7ceBA/MvnP7KAnrUJADpxKv1LKkHbB8Xe+gfog37a1u/h2s4sPvlmWeKamh2axuF49Zvu5a/0qyEhipXqeDizaxVqUzSbBtnlorbSpW93k2hsix0OGxK7VQGrD5BGbRokWMGDGCefPmERkZyaxZs1i8eDHJyck0bFi2z8LWrVvp2bMn8fHx3HfffSxYsIB3332XXbt20bZtWwCOHTtGly5dGD16NMOGDcPDw4ODBw/StWtX8zl79+5NixYteP31183ndnV1vaVvotUnMIoCn/RUq0Z7PA/RU7WOqOopilpduvoVtYnGLxwe+U5dt8gaKYr6X9GaKWAqAq8geGg+BERIbUxtVZQPhv3qB8nZXWq/EWcvtWO5ZwB4+KtrmXkGqPtc6lbvz4KxCM7supKwnN5+5YOtlG+7KwlL4yhwdKu+eLSSlaomNMYiNWmp17R2/w5mparrt+2cr/6jB+pM5OGPqp1+vZvXfEi2nsBERkbSuXNn5syZA4DJZCIwMJDx48fzyitlO58OHTqU3NxcVq5cad7XtWtXwsPDzbUnjzzyCA4ODnzzzTfXfd/evXsTHh7OrFmzKh271ScwAMm/wPePqD+oz+21zqreyiougJ/jYPe36vP2Q+H+/9jGf01nktQ+SqUjKZw91dEL9UPUPySlj+s11a7/jrh1JqM6x0lpsnImCdIOlk0QKmLvUk5ic81jZ6+b/7BVFLVDv7kfyxZ1FMzVPBtDs95qwtKkV832XRE1q+gy7F+s/iN17s8r+0P6qs1LTe+usUTOphOYwsJCXF1d+fHHH4mNjTXvHzlyJBkZGSxfvrzMMY0bNyYuLo4JEyaY97322mssW7aMvXv3YjKZ8PT05P/9v//H5s2b2b17N02aNGHixIkW79G7d28OHjyIoij4+vpy//33M3nyZFxdXa8bb0FBAQUFV9pJs7KyCAwMtO4ERlHgs7vVNt5u46Hvm1pHdPuKC9S5Ida9pU4apdPDva+rE9TZ0n9QlzPUBOzAEq47ikOnV5c8qB8C3iVb/RA1wXHztq3rrW0URU1AzcnKLji7B4rKWcbDrYFayxYQoXb8LMxV+0NlnVWbNkof556/ufd2cFMTGc8ANbG59rGDi2WzUE6a5fEuddVEpWlvaNoL6jaRn6U7jaLA8Y1qInNkNea/QQ1aqR1+2w+t9n8GqyKB0awxMz09HaPRiI+Pj8V+Hx8fDh8+XO4xBoOh3PIGgwGAc+fOkZOTwzvvvMObb77Ju+++y+rVqxk8eDDr1q2jV69eADz66KMEBQXh7+/Pvn37ePnll0lOTmbJkiXXjTc+Pp5p06bdziXXPJ0O7v4/+O4h2P45RI0Hd58bH2dtMlLgrzVwdK36B7n0Q8LZC/7xJTS7R8voKsfFS20+GjQXLhxTJ8VK/0udDKv0cWG22vnw4t9w9FfL4509ryQz3s2vPK7XRF2hXFSt3AtXalXOJKkJS1562XKOddT+EwEd1ZljAyLUJs2bSRCK8iG7NKk5qyY21z6+fFH9+b9wVN1uhr2z2hRU2izk2/7WFi8VtY9OpyavTXupf3+2f6rWZp8/BP97DtZOg4hR0GWMmhRbKRvsjXV9JpMJgEGDBvH8888DEB4eztatW5k3b545gRk7dqz5mHbt2uHn50efPn04duwYzZo1K/fcEydOJC4uzvy8tAbG6jWPVucnOL0DtsyCfvFaR3RjxiJ1OOPR3+DoGsuqTlBn7Ay5F+6KU5tZbJmDizqaw7et5X5FgWxDSTJzRE1oSh9npKhLJJzZqW5XK6/WpkErdUSFlU9sZTUKcyF175VE5UxS2XlGQO3g6ttWTVJKkxXvENDbVe59HZzVn+eKfqaLLpfU3JyGrDPqllnytXR/QZaaRJUmLI26yL0X11e/GfR/F+5+VU1i/pin1i5ufl+dBqJ1LHR9GhpFaB1pGZolMN7e3tjZ2ZGWZlm9mZaWhq9v+RPv+Pr6Vlje29sbe3t7WrdubVGmVatWbN68+bqxREZGAvDXX39dN4FxcnLCyckG/7PV6dQfzG8ehB1fQLdn1ZWUrU22QU1Wjv6m1rIUZF15TadX/wiH3Ku21fq2q/1V3jqdep88/KBJT8vXii7feq2N3kH9vjXqXDIstJPaidiav4+Kos7nYdinTiRWkA0o6v7SKu/yHptbxSsqS9myxqKSNXoOqUtBXMu7xZVEJSBCXSKiphMDBxf1A6d++X+nAHUaBalhEbfK2ROinlE79SavUkcvndwMB35Ut+bRMPxHq/qboVkC4+joSEREBAkJCeb+KSaTiYSEBMaNG1fuMVFRUSQkJFj0gVmzZg1RUVHmc3bu3Jnk5GSL444cOUJQUNB1Y9mzZw8Afn5W+MFeFZrerVYhn0qETTNh4HtaR6TOVXBm55WkxbDP8nVXbzVhaR6tNhHV5mHgt+pWam3Sj6jf29zzahPI2V2w/RO1vFtDNaFp1En9GtBRuxEnxiK1A6xhH6TuK0la9lsmsjXJ3V/9fgRElDQHdbCdIe+SvIjbobeDVverW+peNZE58CN4t7Sq5AWsYBj1yJEj+eSTT+jSpQuzZs3ihx9+4PDhw/j4+DBixAgCAgKIj1ebPbZu3UqvXr145513GDhwIAsXLuTtt9+2GEa9dOlShg4dyty5c7n77rtZvXo1EyZMYP369fTo0YNjx46xYMECBgwYQP369dm3bx/PP/88jRo1KjM3TEVsYhTS1Y5vhK/vVydSG78LvDRo/so5D8cS1ITlr4Rr1hLRqR8UIX3VxMWvg/whriqKojaBnN6pNiWe3qEmCaYiy3I6vVqr0KhzydZF/U+/qv9oFeSoo3MM+9Q/kIZ9as2HsbBsWTtHaNharT0yLwehuyqm0sclz0sfW7zOzZXV6dXmG/+O1llLKYRWcs4BuiodyWrTo5BKzZkzxzyRXXh4OB9++KG5Sad3794EBwfz1VdfmcsvXryYSZMmmSeymz59epmJ7ObPn098fDynT5+mZcuWTJs2jUGDBgGQkpLCP//5Tw4cOEBubi6BgYE8+OCDTJo0qXbNA1Oer+5TZ6b0bAx1g9RZNZ091UXPnD0reF7y+FaH9JpM6gioo7+p29ndWIy4cfZSa1hC+kLzPjJ8syYVXVaTmNKE5vQOtR/FtVzqQkCnK81OARG3VhORm34lSSmtWblwjHJHXjl5qomKbzt1llTf9uoif9Y0XbsQokrUigTGVtlkAnPqD/iyX/nt+zfD3uXmkh07BziZqC5keO1IDd/2JbUsfdUPQ1uc1bO2yjyjNuud3gEpOyB1DxTnX1NIp651U9rs1Kiz+lynU2t5SpOU0q/lrSkD4O6n/ixcnazUDba6KmohRPWQBEZDNpnAgNov4tIJKMhUR7LkZ6lfC7Ku//zaia9uhZMHNLu7pJYl2mpXRhXlKC5Up5Y/vVOdsfX0jrKL5IF6j9GpP1Nl6NRmKItkJax2TaoohLhlksBoyGYTmMowGStOcMzPM0oSnly1g2lIX3VdEWkCqD1yzqu1NCklCc2ZXVfm5bFzVFch9i2pUfFrr/apcXLXNmYhhNWx6YnshA3R26l9IVzqah2J0FqdBtCyv7pByfT5h9WOwt4tZOkDIUSNkQRGCFF5eju1lkUIIWqYjFMVQgghhM2RBEYIIYQQNkcSGCGEEELYHElghBBCCGFzJIERQgghhM2RBEYIIYQQNkcSGCGEEELYHJkHppJKJzDOysrSOBIhhBDCtpR+dt7OYgCSwFRSdra6PlBgYKDGkQghhBC2KTs7G0/PW1jh/iqyFlIlmUwmzp49i7u7O7oqWkE3KyuLwMBAUlJSav/6SleR65brvlPcqdcu1y3XfS1FUcjOzsbf3x+9vnK9WaQGppL0ej2NGjWqlnN7eHjcUT/speS67yx36nXDnXvtct13lhtdd2VrXkpJJ14hhBBC2BxJYIQQQghhcySBsSJOTk689tprODk5aR1KjZLrluu+U9yp1y7XLdddHaQTrxBCCCFsjtTACCGEEMLmSAIjhBBCCJsjCYwQQgghbI4kMEIIIYSwOZLA1LC5c+cSHByMs7MzkZGRbN++vcLyixcvJjQ0FGdnZ9q1a8eqVatqKNKqER8fT+fOnXF3d6dhw4bExsaSnJxc4TFfffUVOp3OYnN2dq6hiKvG1KlTy1xDaGhohcfY+r0uFRwcXObadTodzzzzTLnlbfV+b9y4kfvvvx9/f390Oh3Lli2zeF1RFKZMmYKfnx8uLi5ER0dz9OjRG573Vv9G1LSKrruoqIiXX36Zdu3a4ebmhr+/PyNGjODs2bMVnrMyvy817Ub3e9SoUWWuoV+/fjc8ry3fb6Dc33WdTseMGTOue86qut+SwNSgRYsWERcXx2uvvcauXbsICwsjJiaGc+fOlVt+69atDBs2jNGjR7N7925iY2OJjY3lwIEDNRx55W3YsIFnnnmGbdu2sWbNGoqKiujbty+5ubkVHufh4UFqaqp5O3nyZA1FXHXatGljcQ2bN2++btnacK9L7dixw+K616xZA8A//vGP6x5ji/c7NzeXsLAw5s6dW+7r06dP58MPP2TevHn88ccfuLm5ERMTQ35+/nXPeat/I7RQ0XXn5eWxa9cuJk+ezK5du1iyZAnJyck88MADNzzvrfy+aOFG9xugX79+Ftfw/fffV3hOW7/fgMX1pqamMn/+fHQ6HUOGDKnwvFVyvxVRY7p06aI888wz5udGo1Hx9/dX4uPjyy3/8MMPKwMHDrTYFxkZqfz73/+u1jir07lz5xRA2bBhw3XLfPnll4qnp2fNBVUNXnvtNSUsLOymy9fGe13queeeU5o1a6aYTKZyX68N9xtQli5dan5uMpkUX19fZcaMGeZ9GRkZipOTk/L9999f9zy3+jdCa9ded3m2b9+uAMrJkyevW+ZWf1+0Vt51jxw5Uhk0aNAtnac23u9BgwYp99xzT4Vlqup+Sw1MDSksLCQpKYno6GjzPr1eT3R0NImJieUek5iYaFEeICYm5rrlbUFmZiYA9erVq7BcTk4OQUFBBAYGMmjQIA4ePFgT4VWpo0eP4u/vT9OmTRk+fDinTp26btnaeK9B/bn/9ttv+de//lXhoqe14X5f7fjx4xgMBot76unpSWRk5HXvaWX+RtiCzMxMdDodXl5eFZa7ld8Xa7V+/XoaNmxIy5Yteeqpp7hw4cJ1y9bG+52WlsbPP//M6NGjb1i2Ku63JDA1JD09HaPRiI+Pj8V+Hx8fDAZDuccYDIZbKm/tTCYTEyZMoHv37rRt2/a65Vq2bMn8+fNZvnw53377LSaTiW7dunH69OkajPb2REZG8tVXX7F69Wo+/vhjjh8/zl133UV2dna55WvbvS61bNkyMjIyGDVq1HXL1Ib7fa3S+3Yr97QyfyOsXX5+Pi+//DLDhg2rcFG/W/19sUb9+vXjv//9LwkJCbz77rts2LCB/v37YzQayy1fG+/3119/jbu7O4MHD66wXFXdb1mNWtSYZ555hgMHDtywrTMqKoqoqCjz827dutGqVSs++eQT3njjjeoOs0r079/f/Lh9+/ZERkYSFBTEDz/8cFP/ndQWX3zxBf3798ff3/+6ZWrD/RZlFRUV8fDDD6MoCh9//HGFZWvD78sjjzxiftyuXTvat29Ps2bNWL9+PX369NEwspozf/58hg8ffsNO+FV1v6UGpoZ4e3tjZ2dHWlqaxf60tDR8fX3LPcbX1/eWyluzcePGsXLlStatW0ejRo1u6VgHBwc6dOjAX3/9VU3RVT8vLy9atGhx3WuoTfe61MmTJ1m7di1PPPHELR1XG+536X27lXtamb8R1qo0eTl58iRr1qypsPalPDf6fbEFTZs2xdvb+7rXUJvuN8CmTZtITk6+5d93qPz9lgSmhjg6OhIREUFCQoJ5n8lkIiEhweK/z6tFRUVZlAdYs2bNdctbI0VRGDduHEuXLuX333+nSZMmt3wOo9HI/v378fPzq4YIa0ZOTg7Hjh277jXUhnt9rS+//JKGDRsycODAWzquNtzvJk2a4Ovra3FPs7Ky+OOPP657TyvzN8IalSYvR48eZe3atdSvX/+Wz3Gj3xdbcPr0aS5cuHDda6gt97vUF198QUREBGFhYbd8bKXv9213AxY3beHChYqTk5Py1VdfKX/++acyduxYxcvLSzEYDIqiKMpjjz2mvPLKK+byW7ZsUezt7ZX33ntPOXTokPLaa68pDg4Oyv79+7W6hFv21FNPKZ6ensr69euV1NRU85aXl2cuc+11T5s2Tfn111+VY8eOKUlJScojjzyiODs7KwcPHtTiEirlhRdeUNavX68cP35c2bJlixIdHa14e3sr586dUxSldt7rqxmNRqVx48bKyy+/XOa12nK/s7Ozld27dyu7d+9WAOX9999Xdu/ebR5t88477yheXl7K8uXLlX379imDBg1SmjRpoly+fNl8jnvuuUeZPXu2+fmN/kZYg4quu7CwUHnggQeURo0aKXv27LH4nS8oKDCf49rrvtHvizWo6Lqzs7OVF198UUlMTFSOHz+urF27VunYsaMSEhKi5Ofnm89R2+53qczMTMXV1VX5+OOPyz1Hdd1vSWBq2OzZs5XGjRsrjo6OSpcuXZRt27aZX+vVq5cycuRIi/I//PCD0qJFC8XR0VFp06aN8vPPP9dwxLcHKHf78ssvzWWuve4JEyaYv0c+Pj7KgAEDlF27dtV88Ldh6NChip+fn+Lo6KgEBAQoQ4cOVf766y/z67XxXl/t119/VQAlOTm5zGu15X6vW7eu3J/t0mszmUzK5MmTFR8fH8XJyUnp06dPme9HUFCQ8tprr1nsq+hvhDWo6LqPHz9+3d/5devWmc9x7XXf6PfFGlR03Xl5eUrfvn2VBg0aKA4ODkpQUJAyZsyYMolIbbvfpT755BPFxcVFycjIKPcc1XW/dYqiKLdc3yOEEEIIoSHpAyOEEEIImyMJjBBCCCFsjiQwQgghhLA5ksAIIYQQwuZIAiOEEEIImyMJjBBCCCFsjiQwQgghhLA5ksAIIYQQwuZIAiOEECV0Oh3Lli3TOgwhxE2QBEYIYRVGjRqFTqcrs/Xr10/r0IQQVshe6wCEEKJUv379+PLLLy32OTk5aRSNEMKaSQ2MEMJqODk54evra7HVrVsXUJt3Pv74Y/r374+LiwtNmzblxx9/tDh+//793HPPPbi4uFC/fn3Gjh1LTk6ORZn58+fTpk0bnJyc8PPzY9y4cRavp6en8+CDD+Lq6kpISAgrVqyo3osWQlSKJDBCCJsxefJkhgwZwt69exk+fDiPPPIIhw4dAiA3N5eYmBjq1q3Ljh07WLx4MWvXrrVIUD7++GOeeeYZxo4dy/79+1mxYgXNmze3eI9p06bx8MMPs2/fPgYMGMDw4cO5ePFijV6nEOIm3PL61UIIUQ1Gjhyp2NnZKW5ubhbbW2+9pSiKogDKk08+aXFMZGSk8tRTTymKoiiffvqpUrduXSUnJ8f8+s8//6zo9XrFYDAoiqIo/v7+yv/93/9dNwZAmTRpkvl5Tk6OAii//PJLlV2nEKJqSB8YIYTVuPvuu/n4448t9tWrV8/8OCoqyuK1qKgo9uzZA8ChQ4cICwvDzc3N/Hr37t0xmUwkJyej0+k4e/Ysffr0qTCG9u3bmx+7ubnh4eHBuXPnKntJQohqIgmMEMJquLm5lWnSqSouLi43Vc7BwcHiuU6nw2QyVUdIQojbIH1ghBA2Y9u2bWWet2rVCoBWrVqxd+9ecnNzza9v2bIFvV5Py5YtcXd3Jzg4mISEhBqNWQhRPaQGRghhNQoKCjAYDBb77O3t8fb2BmDx4sV06tSJHj168N1337F9+3a++OILAIYPH85rr73GyJEjmTp1KufPn2f8+PE89thj+Pj4ADB16lSefPJJGjZsSP/+/cnOzmbLli2MHz++Zi9UCHHbJIERQliN1atX4+fnZ7GvZcuWHD58GFBHCC1cuJCnn34aPz8/vv/+e1q3bg2Aq6srv/76K8899xydO3fG1dWVIUOG8P7775vPNXLkSPLz8/nggw948cUX8fb25qGHHqq5CxRCVBmdoiiK1kEIIcSN6HQ6li5dSmxsrNahCCGsgPSBEUIIIYTNkQRGCCGEEDZH+sAIIWyCtHYLIa4mNTBCCCGEsDmSwAghhBDC5kgCI4QQQgibIwmMEEIIIWyOJDBCCCGEsDmSwAghhBDC5kgCI4QQQgibIwmMEEIIIWzO/weuT9OkHHpNqwAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 600x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_losses(train_losses, test_losses)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5q9j-y-W3mx"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "index 3 is out of bounds for axis 0 with size 3",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[249], line 25\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# For each day in the prediction\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m7\u001b[39m):\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m# Append a new row to the DataFrame\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     new_entry \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[1;32m---> 25\u001b[0m         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission_ID\u001b[39m\u001b[38;5;124m'\u001b[39m: [submission_ID], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcity_id\u001b[39m\u001b[38;5;124m'\u001b[39m: [city_id], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: [date], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavg_temp_c\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m]}, index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     26\u001b[0m     submission_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([submission_df, new_entry], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# Increment the submission ID\u001b[39;00m\n",
            "\u001b[1;31mIndexError\u001b[0m: index 3 is out of bounds for axis 0 with size 3"
          ]
        }
      ],
      "source": [
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Initialize an empty DataFrame\n",
        "submission_df = pd.DataFrame(\n",
        "    columns=['submission_ID', 'city_id', 'date', \"avg_temp_c\"])\n",
        "# Initialize an non-empty DataFrame\n",
        "submission_df = pd.DataFrame(\n",
        "    {'submission_ID': [0], 'city_id': ['C000'], 'date': [datetime.strptime('2019-01-01', '%Y-%m-%d')], \"avg_temp_c\": [0.0]})\n",
        "\n",
        "# Initialize the submission ID\n",
        "submission_ID = 1\n",
        "date = datetime.strptime('2019-01-01', '%Y-%m-%d')\n",
        "# Iterate over the list of sequences\n",
        "for i, (inputs,) in enumerate(predict_loader):\n",
        "    # Generate the city_id\n",
        "    city_id = 'C' + str(i+1).zfill(3)\n",
        "\n",
        "    # Use the model to predict the next 14 days\n",
        "    predictions = model(inputs)\n",
        "    predictions = predictions.detach().cpu().numpy().flatten()\n",
        "    # For each day in the prediction\n",
        "    for j in range(7):\n",
        "        # Append a new row to the DataFrame\n",
        "        new_entry = pd.DataFrame(\n",
        "            {'submission_ID': [submission_ID], 'city_id': [city_id], 'date': [date], \"avg_temp_c\": [predictions[j]]}, index=[0])\n",
        "        submission_df = pd.concat([submission_df, new_entry], ignore_index=True)\n",
        "        # Increment the submission ID\n",
        "        date += timedelta(days=1)\n",
        "        submission_ID += 1\n",
        "    date = datetime.strptime('2019-01-01', '%Y-%m-%d')\n",
        "# Drop the initial row\n",
        "submission_df = submission_df.iloc[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RYLflxXW3mx",
        "outputId": "ee611904-01ad-4b39-cfdb-c0e317121bef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     submission_ID city_id       date  avg_temp_c\n",
            "1                1    C001 2019-01-01   -0.823072\n",
            "2                2    C001 2019-01-02   -0.869276\n",
            "3                3    C001 2019-01-03   -0.893562\n",
            "4                4    C002 2019-01-01   -0.451946\n",
            "5                5    C002 2019-01-02   -0.476310\n",
            "..             ...     ...        ...         ...\n",
            "296            296    C099 2019-01-02    0.843215\n",
            "297            297    C099 2019-01-03    0.834449\n",
            "298            298    C100 2019-01-01    0.177258\n",
            "299            299    C100 2019-01-02    0.172073\n",
            "300            300    C100 2019-01-03    0.169280\n",
            "\n",
            "[300 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "print(submission_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7CCxHnDLbo3"
      },
      "outputs": [],
      "source": [
        "y_pred_original_scale_placeholder = np.zeros((submission_df.shape[0], 10))\n",
        "\n",
        "y_pred_original_scale_placeholder[:, 0] = submission_df['avg_temp_c'].values\n",
        "\n",
        "y_pred_original_scale = scaler.inverse_transform(y_pred_original_scale_placeholder)\n",
        "\n",
        "y_pred_original_scale = y_pred_original_scale[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pJDX4nVKoif",
        "outputId": "721c5d2c-4305-41fb-e4e7-341bdbfa4b53"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-8.23071659e-01, -8.69275987e-01, -8.93562198e-01, -4.51945752e-01,\n",
              "       -4.76310283e-01, -4.90191042e-01,  8.10003519e-01,  8.01829815e-01,\n",
              "        7.98521459e-01, -1.92661572e+00, -1.92164743e+00, -1.91592145e+00,\n",
              "        5.58891237e-01,  5.39128959e-01,  5.28744757e-01,  1.21643454e-01,\n",
              "        8.58997107e-02,  6.52710944e-02, -1.46558404e+00, -1.49357271e+00,\n",
              "       -1.50586951e+00, -6.44129515e-03,  4.21374477e-03,  9.54307616e-03,\n",
              "       -8.73841941e-02, -8.20717961e-02, -7.97066092e-02, -1.91437423e+00,\n",
              "       -1.90851057e+00, -1.90060687e+00, -9.32982981e-01, -1.02353406e+00,\n",
              "       -1.07184362e+00, -1.30313468e+00, -1.31693256e+00, -1.32146680e+00,\n",
              "       -1.45575190e+00, -1.46513093e+00, -1.46708167e+00,  5.73443532e-01,\n",
              "        5.58725417e-01,  5.51148236e-01,  1.78805158e-01,  1.58161551e-01,\n",
              "        1.46011546e-01,  7.02554762e-01,  6.91428959e-01,  6.86267912e-01,\n",
              "       -1.73189819e+00, -1.75390565e+00, -1.76190341e+00,  6.60475373e-01,\n",
              "        6.41941786e-01,  6.32593751e-01, -2.35888219e+00, -2.35751796e+00,\n",
              "       -2.35216260e+00,  8.42875063e-01,  8.22472811e-01,  8.12122166e-01,\n",
              "       -9.20526922e-01, -9.96546805e-01, -1.03622937e+00, -9.39158618e-01,\n",
              "       -1.04706347e+00, -1.10416257e+00, -2.89186358e+00, -2.88150740e+00,\n",
              "       -2.87578368e+00,  6.89193726e-01,  6.81828737e-01,  6.78703725e-01,\n",
              "        6.32551670e-01,  6.10790849e-01,  5.99326193e-01,  8.62411141e-01,\n",
              "        8.52991879e-01,  8.49085987e-01, -1.72402787e+00, -1.76118028e+00,\n",
              "       -1.77791142e+00, -1.71838427e+00, -1.74574113e+00, -1.75738513e+00,\n",
              "       -8.71789813e-01, -9.57184494e-01, -1.00273848e+00,  9.09123480e-01,\n",
              "        8.96426082e-01,  8.90662670e-01, -2.07825518e+00, -2.03703046e+00,\n",
              "       -2.00971341e+00, -9.28059816e-01, -1.03278196e+00, -1.08832836e+00,\n",
              "        9.08784866e-01,  9.03649986e-01,  9.02071595e-01, -6.08163774e-01,\n",
              "       -6.40850246e-01, -6.58447087e-01,  9.03597414e-01,  8.89125526e-01,\n",
              "        8.82510602e-01,  2.27229595e-01,  2.07356781e-01,  1.96055114e-01,\n",
              "       -1.41080236e+00, -1.45408762e+00, -1.47507918e+00, -6.94050491e-01,\n",
              "       -7.11395860e-01, -7.19373763e-01,  7.68531203e-01,  7.66695380e-01,\n",
              "        7.66961813e-01, -1.43091202e+00, -1.41060841e+00, -1.39674377e+00,\n",
              "       -1.29208815e+00, -1.30613983e+00, -1.31072676e+00, -6.05156779e-01,\n",
              "       -6.71211123e-01, -7.06919551e-01, -1.34656274e+00, -1.32601523e+00,\n",
              "       -1.31177211e+00,  9.24912393e-01,  9.12900388e-01,  9.07479465e-01,\n",
              "       -1.96801007e+00, -2.01366353e+00, -2.03674912e+00, -1.82281721e+00,\n",
              "       -1.84659278e+00, -1.85537088e+00, -1.04506910e+00, -1.13322294e+00,\n",
              "       -1.17976069e+00, -1.73218834e+00, -1.67210770e+00, -1.63539028e+00,\n",
              "        3.36964548e-01,  3.10508937e-01,  2.95584232e-01,  6.63263917e-01,\n",
              "        6.41231537e-01,  6.29675925e-01, -5.11924148e-01, -5.08301795e-01,\n",
              "       -5.06258726e-01,  3.50639105e-01,  3.57590109e-01,  3.62007827e-01,\n",
              "       -6.69064224e-01, -6.92717552e-01, -7.05112755e-01, -8.87510419e-01,\n",
              "       -9.36656058e-01, -9.62117136e-01, -6.21886015e-01, -6.36685729e-01,\n",
              "       -6.44416094e-01,  4.99021858e-01,  5.07403553e-01,  5.13093472e-01,\n",
              "        4.40357566e-01,  4.35743362e-01,  4.33567435e-01, -9.58013713e-01,\n",
              "       -9.59916115e-01, -9.59620416e-01, -2.57054299e-01, -2.30574831e-01,\n",
              "       -2.16235831e-01,  7.79673576e-01,  7.63402522e-01,  7.55274057e-01,\n",
              "        5.15382051e-01,  5.08274674e-01,  5.04957914e-01, -2.40292192e+00,\n",
              "       -2.40574622e+00, -2.40395212e+00, -1.65989256e+00, -1.70863032e+00,\n",
              "       -1.73199368e+00,  4.49395418e-01,  4.52860624e-01,  4.55404311e-01,\n",
              "        8.01527858e-01,  7.88598061e-01,  7.82538474e-01, -1.19794261e+00,\n",
              "       -1.28030741e+00, -1.32288945e+00,  9.43703577e-04,  7.46159442e-03,\n",
              "        1.04091130e-02, -1.34604836e+00, -1.38129652e+00, -1.39820457e+00,\n",
              "        1.46220773e-01,  1.22278169e-01,  1.08170018e-01,  7.42860436e-01,\n",
              "        7.28465080e-01,  7.21440136e-01,  9.00464714e-01,  8.92567575e-01,\n",
              "        8.89318883e-01, -1.07761705e+00, -1.08849728e+00, -1.09153569e+00,\n",
              "       -6.47233069e-01, -6.50270283e-01, -6.52529001e-01,  5.62064171e-01,\n",
              "        5.56975007e-01,  5.54953635e-01, -8.56362045e-01, -9.15926814e-01,\n",
              "       -9.46707428e-01,  9.05070007e-01,  8.88278425e-01,  8.80299389e-01,\n",
              "        8.24370742e-01,  8.10593426e-01,  8.03997576e-01, -1.00252092e+00,\n",
              "       -1.07893825e+00, -1.11861551e+00,  8.36695790e-01,  8.34086537e-01,\n",
              "        8.33925068e-01,  5.14387339e-02,  6.44536391e-02,  7.09783435e-02,\n",
              "       -2.01399803e+00, -2.04308796e+00, -2.05617714e+00, -1.18930638e+00,\n",
              "       -1.19074965e+00, -1.18884754e+00,  7.77366519e-01,  7.73433387e-01,\n",
              "        7.72480190e-01,  4.26422566e-01,  3.95457357e-01,  3.78016770e-01,\n",
              "       -1.57372081e+00, -1.63003922e+00, -1.65835083e+00, -1.29219592e+00,\n",
              "       -1.27264619e+00, -1.25885642e+00, -1.69182098e+00, -1.62992477e+00,\n",
              "       -1.59158850e+00,  5.33617020e-01,  4.91643995e-01,  4.68259007e-01,\n",
              "        6.97091758e-01,  6.88935220e-01,  6.85337484e-01, -1.62563336e+00,\n",
              "       -1.59245729e+00, -1.57051313e+00, -1.59695029e+00, -1.55011630e+00,\n",
              "       -1.52117324e+00,  9.11017060e-01,  9.02553439e-01,  8.99117291e-01,\n",
              "       -1.47543275e+00, -1.51335740e+00, -1.53076601e+00,  2.50502199e-01,\n",
              "        2.38370970e-01,  2.31366411e-01, -9.92463350e-01, -1.05196738e+00,\n",
              "       -1.08258641e+00,  2.20560700e-01,  1.99340254e-01,  1.87832832e-01,\n",
              "       -1.90018213e+00, -1.83962131e+00, -1.80134881e+00,  7.91693091e-01,\n",
              "        7.70686626e-01,  7.59950995e-01,  8.60795736e-01,  8.43215227e-01,\n",
              "        8.34448755e-01,  1.77258432e-01,  1.72072664e-01,  1.69280201e-01])"
            ]
          },
          "execution_count": 245,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_original_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "CGpnb1nDMSih",
        "outputId": "04a49eb6-793a-4c3c-c26f-a5758f3f0328"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>avg_temp_c</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.832835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.875795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.912835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.406679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.427342</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>0.824845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>0.821979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>0.160783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>0.173780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>0.181424</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>300 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     avg_temp_c\n",
              "0     -0.832835\n",
              "1     -0.875795\n",
              "2     -0.912835\n",
              "3     -0.406679\n",
              "4     -0.427342\n",
              "..          ...\n",
              "295    0.824845\n",
              "296    0.821979\n",
              "297    0.160783\n",
              "298    0.173780\n",
              "299    0.181424\n",
              "\n",
              "[300 rows x 1 columns]"
            ]
          },
          "execution_count": 203,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred_original_scale = pd.DataFrame(y_pred_original_scale, columns=['avg_temp_c'])\n",
        "y_pred_original_scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxX2ZpPsMeVz"
      },
      "outputs": [],
      "source": [
        "\n",
        "y_pred_original_scale.to_csv('time_ans_8_10.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15cIrnx1xy3K"
      },
      "outputs": [],
      "source": [
        "# from sklearn.ensemble import StackingRegressor\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "# from sklearn.svm import SVR\n",
        "# from sklearn.tree import DecisionTreeRegressor\n",
        "# # from sklearn.datasets import load_boston\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# # Load dataset\n",
        "# # X, y = load_boston(return_X_y=True)\n",
        "\n",
        "# # Split dataset\n",
        "# # X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Define base models\n",
        "# base_models = [\n",
        "#     ('lr', LinearRegression()),\n",
        "#     ('svr', SVR()),\n",
        "#     ('dt', DecisionTreeRegressor())\n",
        "# ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hohDvtjJyVvC"
      },
      "outputs": [],
      "source": [
        "# # Define the Stacking Regressor\n",
        "# model = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
        "\n",
        "# # Convert PyTorch tensors to NumPy arrays for sklearn\n",
        "# # Note: This step assumes X_train_tensor, y_train_tensor, X_test_tensor, y_test_tensor are already defined as in your snippet\n",
        "# X_train_np = X_train_tensor.cpu().detach().numpy()\n",
        "# y_train_np = y_train_tensor.cpu().detach().numpy()\n",
        "# X_test_np = X_test_tensor.cpu().detach().numpy()\n",
        "# y_test_np = y_test_tensor.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L9HlY1Cz61f"
      },
      "outputs": [],
      "source": [
        "# X_train_flattened = X_train.reshape(X_train.shape[0], -1)\n",
        "# y_train_flattened = y_train.reshape(X_train.shape[0], -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1z7Y_qA1Bco"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "Z7opiCt9z5al",
        "outputId": "a037147b-0292-48c0-cc2e-f60536ca9426"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "y should be a 1d array, got an array of shape (142990, 7) instead.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e0e87f52cbdb>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the Stacking Regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_flattened\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_flattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# predictions = model.predict(X_test_np)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfitted\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m         \"\"\"\n\u001b[0;32m--> 957\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (142990, 7) instead."
          ]
        }
      ],
      "source": [
        "# # Fit the Stacking Regressor\n",
        "# model.fit(X_train_flattened, y_train_flattened)\n",
        "\n",
        "# # Make predictions\n",
        "# # predictions = model.predict(X_test_np)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "U_9DcfZCW3my",
        "outputId": "52aed658-d4e7-48c8-83b0-3dd54d585318"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Expected 2D array, got 1D array instead:\narray=[-1.24465196 -1.61516423 -1.18124567 ...  1.64904362  1.58756233\n  1.43095812].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-c19b63511285>\u001b[0m in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# Initialize and train the Stacking model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStackingRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Make predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    956\u001b[0m         \"\"\"\n\u001b[1;32m    957\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 958\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0;31m# base estimators will be used in transform, predict, and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m             \u001b[0;31m# predict_proba. They are exposed publicly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m             self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n\u001b[0m\u001b[1;32m    210\u001b[0m                 \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fit_single_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_estimators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         )\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py\u001b[0m in \u001b[0;36m_fit_single_estimator\u001b[0;34m(estimator, X, y, sample_weight, message_clsname, message)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0maccept_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositive\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"coo\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         X, y = self._validate_data(\n\u001b[0m\u001b[1;32m    649\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1104\u001b[0m         )\n\u001b[1;32m   1105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m     X = check_array(\n\u001b[0m\u001b[1;32m   1107\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0;31m# If input is 1D raise error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m    903\u001b[0m                     \u001b[0;34m\"Expected 2D array, got 1D array instead:\\narray={}.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-1.24465196 -1.61516423 -1.18124567 ...  1.64904362  1.58756233\n  1.43095812].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ],
      "source": [
        "# # Initialize and train the Stacking model\n",
        "# model = StackingRegressor(estimators=base_models, final_estimator=LinearRegression())\n",
        "# model.fit(X_train.flatten(), y_train.flatten())\n",
        "\n",
        "# # Make predictions\n",
        "# predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6KatsZ9xLA4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
